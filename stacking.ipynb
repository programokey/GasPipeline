{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston, load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(data.DESCR)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "train_X,test_X, train_y,  test_y  = train_test_split(data.data,data.target, test_size=0.2, random_state=42, shuffle=True)\n",
    "train_X, validate_X, train_y,  validate_y = train_test_split(train_X, train_y, test_size=0.25, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "C:\\Users\\limuf\\Anaconda3\\Lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "C:\\Users\\limuf\\Anaconda3\\Lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "[1]\ttraining's l2: 52.0229\tvalid_1's l2: 49.8547\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\ttraining's l2: 32.5724\tvalid_1's l2: 34.7255\n",
      "[3]\ttraining's l2: 22.7636\tvalid_1's l2: 27.7439\n",
      "[4]\ttraining's l2: 17.135\tvalid_1's l2: 22.4719\n",
      "[5]\ttraining's l2: 14.1091\tvalid_1's l2: 20.065\n",
      "[6]\ttraining's l2: 12.2844\tvalid_1's l2: 18.7452\n",
      "[7]\ttraining's l2: 10.4471\tvalid_1's l2: 16.6091\n",
      "[8]\ttraining's l2: 8.99057\tvalid_1's l2: 15.4185\n",
      "[9]\ttraining's l2: 8.37676\tvalid_1's l2: 14.9135\n",
      "[10]\ttraining's l2: 7.66913\tvalid_1's l2: 14.8714\n",
      "[11]\ttraining's l2: 7.23623\tvalid_1's l2: 14.5292\n",
      "[12]\ttraining's l2: 6.836\tvalid_1's l2: 14.2767\n",
      "[13]\ttraining's l2: 6.51385\tvalid_1's l2: 14.1769\n",
      "[14]\ttraining's l2: 6.11447\tvalid_1's l2: 13.5908\n",
      "[15]\ttraining's l2: 5.69775\tvalid_1's l2: 13.2734\n",
      "[16]\ttraining's l2: 5.50663\tvalid_1's l2: 13.1714\n",
      "[17]\ttraining's l2: 5.18788\tvalid_1's l2: 12.9715\n",
      "[18]\ttraining's l2: 4.95285\tvalid_1's l2: 13.1308\n",
      "[19]\ttraining's l2: 4.61744\tvalid_1's l2: 13.7021\n",
      "[20]\ttraining's l2: 4.42323\tvalid_1's l2: 13.7842\n",
      "[21]\ttraining's l2: 4.22475\tvalid_1's l2: 13.7306\n",
      "[22]\ttraining's l2: 3.98158\tvalid_1's l2: 13.7184\n",
      "[23]\ttraining's l2: 3.83788\tvalid_1's l2: 13.7159\n",
      "[24]\ttraining's l2: 3.69746\tvalid_1's l2: 13.8394\n",
      "[25]\ttraining's l2: 3.54634\tvalid_1's l2: 13.6785\n",
      "[26]\ttraining's l2: 3.41409\tvalid_1's l2: 13.9899\n",
      "[27]\ttraining's l2: 3.30709\tvalid_1's l2: 14.0365\n",
      "[28]\ttraining's l2: 3.18346\tvalid_1's l2: 13.9516\n",
      "[29]\ttraining's l2: 3.09484\tvalid_1's l2: 14.0158\n",
      "[30]\ttraining's l2: 3.00796\tvalid_1's l2: 13.9818\n",
      "[31]\ttraining's l2: 2.87899\tvalid_1's l2: 13.7301\n",
      "[32]\ttraining's l2: 2.78905\tvalid_1's l2: 13.7468\n",
      "[33]\ttraining's l2: 2.68565\tvalid_1's l2: 13.7227\n",
      "[34]\ttraining's l2: 2.56296\tvalid_1's l2: 13.8765\n",
      "[35]\ttraining's l2: 2.48063\tvalid_1's l2: 13.9166\n",
      "[36]\ttraining's l2: 2.39694\tvalid_1's l2: 14.0833\n",
      "[37]\ttraining's l2: 2.33084\tvalid_1's l2: 13.9496\n",
      "[38]\ttraining's l2: 2.21803\tvalid_1's l2: 14.029\n",
      "[39]\ttraining's l2: 2.12753\tvalid_1's l2: 14.0991\n",
      "[40]\ttraining's l2: 2.05625\tvalid_1's l2: 14.0235\n",
      "[41]\ttraining's l2: 2.00181\tvalid_1's l2: 13.9586\n",
      "[42]\ttraining's l2: 1.94489\tvalid_1's l2: 14.1073\n",
      "[43]\ttraining's l2: 1.89062\tvalid_1's l2: 14.0759\n",
      "[44]\ttraining's l2: 1.83946\tvalid_1's l2: 14.1066\n",
      "[45]\ttraining's l2: 1.78519\tvalid_1's l2: 14.1102\n",
      "[46]\ttraining's l2: 1.72508\tvalid_1's l2: 14.1119\n",
      "[47]\ttraining's l2: 1.66517\tvalid_1's l2: 14.058\n",
      "[48]\ttraining's l2: 1.6014\tvalid_1's l2: 13.8779\n",
      "[49]\ttraining's l2: 1.55012\tvalid_1's l2: 13.8374\n",
      "[50]\ttraining's l2: 1.5066\tvalid_1's l2: 13.735\n",
      "[51]\ttraining's l2: 1.45216\tvalid_1's l2: 13.743\n",
      "[52]\ttraining's l2: 1.41549\tvalid_1's l2: 13.7675\n",
      "[53]\ttraining's l2: 1.37978\tvalid_1's l2: 13.7864\n",
      "[54]\ttraining's l2: 1.33412\tvalid_1's l2: 13.5987\n",
      "[55]\ttraining's l2: 1.30244\tvalid_1's l2: 13.6135\n",
      "[56]\ttraining's l2: 1.26603\tvalid_1's l2: 13.6111\n",
      "[57]\ttraining's l2: 1.21009\tvalid_1's l2: 13.5276\n",
      "[58]\ttraining's l2: 1.18216\tvalid_1's l2: 13.5144\n",
      "[59]\ttraining's l2: 1.15212\tvalid_1's l2: 13.5843\n",
      "[60]\ttraining's l2: 1.1221\tvalid_1's l2: 13.6191\n",
      "[61]\ttraining's l2: 1.09757\tvalid_1's l2: 13.5281\n",
      "[62]\ttraining's l2: 1.07244\tvalid_1's l2: 13.5376\n",
      "[63]\ttraining's l2: 1.04054\tvalid_1's l2: 13.4732\n",
      "[64]\ttraining's l2: 1.01564\tvalid_1's l2: 13.4871\n",
      "[65]\ttraining's l2: 0.989639\tvalid_1's l2: 13.5884\n",
      "[66]\ttraining's l2: 0.961731\tvalid_1's l2: 13.4519\n",
      "[67]\ttraining's l2: 0.942558\tvalid_1's l2: 13.4758\n",
      "[68]\ttraining's l2: 0.923199\tvalid_1's l2: 13.4598\n",
      "[69]\ttraining's l2: 0.890684\tvalid_1's l2: 13.3637\n",
      "[70]\ttraining's l2: 0.870786\tvalid_1's l2: 13.4099\n",
      "[71]\ttraining's l2: 0.850156\tvalid_1's l2: 13.3422\n",
      "[72]\ttraining's l2: 0.831989\tvalid_1's l2: 13.406\n",
      "[73]\ttraining's l2: 0.81009\tvalid_1's l2: 13.3172\n",
      "[74]\ttraining's l2: 0.777205\tvalid_1's l2: 13.2465\n",
      "[75]\ttraining's l2: 0.755862\tvalid_1's l2: 13.2908\n",
      "[76]\ttraining's l2: 0.730237\tvalid_1's l2: 13.2824\n",
      "[77]\ttraining's l2: 0.710289\tvalid_1's l2: 13.2899\n",
      "[78]\ttraining's l2: 0.691263\tvalid_1's l2: 13.1949\n",
      "[79]\ttraining's l2: 0.676004\tvalid_1's l2: 13.1763\n",
      "[80]\ttraining's l2: 0.657098\tvalid_1's l2: 13.2459\n",
      "[81]\ttraining's l2: 0.633597\tvalid_1's l2: 13.198\n",
      "[82]\ttraining's l2: 0.614814\tvalid_1's l2: 13.1185\n",
      "[83]\ttraining's l2: 0.600657\tvalid_1's l2: 13.0665\n",
      "[84]\ttraining's l2: 0.588766\tvalid_1's l2: 13.0543\n",
      "[85]\ttraining's l2: 0.572447\tvalid_1's l2: 13.0625\n",
      "[86]\ttraining's l2: 0.556308\tvalid_1's l2: 13.039\n",
      "[87]\ttraining's l2: 0.544449\tvalid_1's l2: 13.0201\n",
      "[88]\ttraining's l2: 0.531782\tvalid_1's l2: 13.0661\n",
      "[89]\ttraining's l2: 0.521276\tvalid_1's l2: 13.0876\n",
      "[90]\ttraining's l2: 0.510248\tvalid_1's l2: 13.0961\n",
      "[91]\ttraining's l2: 0.498326\tvalid_1's l2: 13.0433\n",
      "[92]\ttraining's l2: 0.488599\tvalid_1's l2: 13.0795\n",
      "[93]\ttraining's l2: 0.476297\tvalid_1's l2: 13.0243\n",
      "[94]\ttraining's l2: 0.461744\tvalid_1's l2: 13.0541\n",
      "[95]\ttraining's l2: 0.449062\tvalid_1's l2: 13.0172\n",
      "[96]\ttraining's l2: 0.436837\tvalid_1's l2: 13.0786\n",
      "[97]\ttraining's l2: 0.424308\tvalid_1's l2: 13.0855\n",
      "[98]\ttraining's l2: 0.416493\tvalid_1's l2: 13.1295\n",
      "[99]\ttraining's l2: 0.405463\tvalid_1's l2: 13.1182\n",
      "[100]\ttraining's l2: 0.395876\tvalid_1's l2: 13.165\n",
      "[101]\ttraining's l2: 0.388562\tvalid_1's l2: 13.1704\n",
      "[102]\ttraining's l2: 0.380616\tvalid_1's l2: 13.1899\n",
      "[103]\ttraining's l2: 0.374522\tvalid_1's l2: 13.1643\n",
      "[104]\ttraining's l2: 0.365918\tvalid_1's l2: 13.1539\n",
      "[105]\ttraining's l2: 0.356915\tvalid_1's l2: 13.1676\n",
      "[106]\ttraining's l2: 0.349878\tvalid_1's l2: 13.1324\n",
      "[107]\ttraining's l2: 0.344008\tvalid_1's l2: 13.1692\n",
      "[108]\ttraining's l2: 0.33545\tvalid_1's l2: 13.177\n",
      "[109]\ttraining's l2: 0.329707\tvalid_1's l2: 13.1709\n",
      "[110]\ttraining's l2: 0.319356\tvalid_1's l2: 13.1428\n",
      "[111]\ttraining's l2: 0.311939\tvalid_1's l2: 13.1594\n",
      "[112]\ttraining's l2: 0.302655\tvalid_1's l2: 13.1227\n",
      "[113]\ttraining's l2: 0.29675\tvalid_1's l2: 13.1022\n",
      "[114]\ttraining's l2: 0.29217\tvalid_1's l2: 13.0956\n",
      "[115]\ttraining's l2: 0.285013\tvalid_1's l2: 13.0963\n",
      "[116]\ttraining's l2: 0.278885\tvalid_1's l2: 13.0687\n",
      "[117]\ttraining's l2: 0.273849\tvalid_1's l2: 13.0838\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's l2: 5.18788\tvalid_1's l2: 12.9715\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-30f8873d864e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'objective'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'regression'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'num_iterations'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'num_leaves'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'metric'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mrt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesting_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mrt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'data'"
     ],
     "ename": "TypeError",
     "evalue": "predict() missing 1 required positional argument: 'data'",
     "output_type": "error"
    }
   ],
   "source": [
    "training_data = lgb.Dataset(data=train_X, label=train_y.squeeze(), categorical_feature=[3, 8])\n",
    "testing_data = lgb.Dataset(data=validate_X, label=validate_y.squeeze(), categorical_feature=[3, 8])\n",
    "store = {}\n",
    "\n",
    "params = {'objective':'regression', 'num_iterations':300, 'learning_rate':0.3, 'num_leaves':100000, 'metric':'l2'}\n",
    "rt = lgb.train(params=params, train_set=training_data, valid_sets=[training_data, testing_data], early_stopping_rounds=100)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "(43.910947255937934, (1, 14), 17)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 35
    }
   ],
   "source": [
    "k = 233\n",
    "contribute = rt.predict(data.data[k:k + 1,:], raw_score=True, pred_contrib=True)\n",
    "contribute.sum(), contribute.shape, rt.num_trees()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "k = 233\n",
    "leaf = rt.predict(data.data[k:k + 1,:], raw_score=True, pred_leaf=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[29.236942049717694, 4.766395582471575, 3.2633113114730175, 2.0712735360318963, 1.8391251010554177, 1.1139755263924598, 1.1210216611357673, 0.7847151651978492, 0.4324425732959872, -0.3656373962759972, -0.3357709317539747, 0.38303897086530925, -0.3439648206345737, 0.31538343007930303, -0.27129329634564264, 0.21849834139530475, -0.31850954816346205]\n",
      "43.91094725593792\n",
      "[43.91094726]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "leaves_output = [rt.get_leaf_output(tree_id=i, leaf_id=leaf_id) for i, leaf_id in enumerate(leaf.reshape(-1))]\n",
    "print(leaves_output)\n",
    "print(sum(leaves_output))\n",
    "print(rt.predict(data.data[k:k + 1,:], raw_score=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import itertools\n",
    "class StackingModel:\n",
    "    pass\n",
    "\n",
    "class LGBStacking:\n",
    "    def __init__(self, lgb_params, stacking_params=None):\n",
    "        self.stacking_params = stacking_params if stacking_params is not None else {}\n",
    "        self.lgb_params = lgb_params\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_intermediate_representation(rt, X):\n",
    "        #type:(lgb.Booster, np.ndarray)->np.ndarray\n",
    "        intermediate_representation = np.zeros((X.shape[0], rt.num_trees()), dtype=np.float32)\n",
    "        pred_leaves = rt.predict(X, pred_leaf=True)\n",
    "        for i, j in itertools.product(range(X.shape[0]), range(rt.num_trees())):\n",
    "            intermediate_representation[i, j] = rt.get_leaf_output(tree_id=j, leaf_id=pred_leaves[i, j])\n",
    "        return intermediate_representation\n",
    "    \n",
    "    def eval(self, rt, X, y, metric='L2'):\n",
    "        #type: (lgb.Booster, np.ndarray, np.ndarray, str)->np.ndarray\n",
    "        y_pred = rt.predict(data=X)\n",
    "        if metric == 'L2':\n",
    "            return np.mean(np.square(y_pred - y))\n",
    "    \n",
    "    def train(self, X, y, validate_size=0.25, random_state=None, shuffle=True,  categorical_feature='auto'):\n",
    "        train_X, test_X, train_y, test_y  = train_test_split(X,y, test_size=validate_size, random_state=random_state, shuffle=shuffle)\n",
    "        self.layers = []\n",
    "        performance = []\n",
    "        min_loss = 1e9\n",
    "        count = 0\n",
    "        best_round = 0\n",
    "        for layers in range(self.stacking_params.get('maximum_layers', 5)):\n",
    "            if len(self.layers) > 0:\n",
    "                rt = self.layers[-1]\n",
    "                train_X_intermediate = LGBStacking.get_intermediate_representation(rt, train_X)\n",
    "                test_X_intermediate = LGBStacking.get_intermediate_representation(rt, test_X)\n",
    "                train_X = np.hstack((train_X, train_X_intermediate))\n",
    "                test_X = np.hstack((test_X, test_X_intermediate))\n",
    "            training_data = lgb.Dataset(data=train_X, label=train_y.squeeze(), categorical_feature=categorical_feature)\n",
    "            testing_data = lgb.Dataset(data=test_X, label=test_y.squeeze(), categorical_feature=categorical_feature)\n",
    "            rt = lgb.train(params=self.lgb_params, train_set=training_data, valid_sets=[training_data, testing_data])\n",
    "            self.layers.append(rt)\n",
    "            performance.append(self.eval(rt, test_X, test_y))\n",
    "            if min_loss > performance[-1]:\n",
    "                count = 0\n",
    "                min_loss = performance[-1]\n",
    "                best_round = layers\n",
    "            else:\n",
    "                count += 1\n",
    "                if count > self.stacking_params.get('min_early_stopping_layers', 2) \\\n",
    "                        and count == self.stacking_params.get('early_stopping_round', 2):\n",
    "                    self.layers = self.layers[:best_round + 1]\n",
    "                    return \n",
    "            \n",
    "    \n",
    "    def predict(self, X):\n",
    "        for i, rt in enumerate(self.layers):\n",
    "            if  i < len(self.layers) - 1:\n",
    "                X_intermediate = LGBStacking.get_intermediate_representation(rt, X)\n",
    "                X = np.hstack((X, X_intermediate))\n",
    "            else:\n",
    "                y = rt.predict(X)\n",
    "                return y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "params = {'objective':'regression', 'num_iterations':300, 'learning_rate':0.1, 'num_leaves':1000, 'metric':'l2'}\n",
    "stacking = LGBStacking(lgb_params=params)\n",
    "train_X,test_X, train_y,  test_y  = train_test_split(data.data,data.target, test_size=0.2, random_state=42, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "[1]\ttraining's l2: 71.8998\tvalid_1's l2: 83.2917\n",
      "[2]\ttraining's l2: 61.6804\tvalid_1's l2: 74.6162\n",
      "[3]\ttraining's l2: 53.1023\tvalid_1's l2: 66.6323\n",
      "[4]\ttraining's l2: 46.1637\tvalid_1's l2: 60.0965\n",
      "[5]\ttraining's l2: 40.325\tvalid_1's l2: 55.12\n",
      "[6]\ttraining's l2: 35.4066\tvalid_1's l2: 50.1646\n",
      "[7]\ttraining's l2: 31.5398\tvalid_1's l2: 46.8128\n",
      "[8]\ttraining's l2: 28.1115\tvalid_1's l2: 43.2399\n",
      "[9]\ttraining's l2: 25.1459\tvalid_1's l2: 39.7494\n",
      "[10]\ttraining's l2: 22.8672\tvalid_1's l2: 36.4931\n",
      "[11]\ttraining's l2: 21.0206\tvalid_1's l2: 33.945\n",
      "[12]\ttraining's l2: 19.2772\tvalid_1's l2: 31.9091\n",
      "[13]\ttraining's l2: 17.8933\tvalid_1's l2: 29.8747\n",
      "[14]\ttraining's l2: 16.4811\tvalid_1's l2: 28.0929\n",
      "[15]\ttraining's l2: 15.3204\tvalid_1's l2: 26.6456\n",
      "[16]\ttraining's l2: 14.4379\tvalid_1's l2: 25.4303\n",
      "[17]\ttraining's l2: 13.6055\tvalid_1's l2: 24.3157\n",
      "[18]\ttraining's l2: 12.9111\tvalid_1's l2: 23.4678\n",
      "[19]\ttraining's l2: 12.2994\tvalid_1's l2: 22.8089\n",
      "[20]\ttraining's l2: 11.7124\tvalid_1's l2: 21.9733\n",
      "[21]\ttraining's l2: 11.2952\tvalid_1's l2: 21.2373\n",
      "[22]\ttraining's l2: 10.8776\tvalid_1's l2: 20.8636\n",
      "[23]\ttraining's l2: 10.4876\tvalid_1's l2: 20.3656\n",
      "[24]\ttraining's l2: 10.2008\tvalid_1's l2: 19.9868\n",
      "[25]\ttraining's l2: 9.90739\tvalid_1's l2: 19.5898\n",
      "[26]\ttraining's l2: 9.66022\tvalid_1's l2: 19.2544\n",
      "[27]\ttraining's l2: 9.35884\tvalid_1's l2: 18.9211\n",
      "[28]\ttraining's l2: 9.08513\tvalid_1's l2: 18.6379\n",
      "[29]\ttraining's l2: 8.82877\tvalid_1's l2: 18.6015\n",
      "[30]\ttraining's l2: 8.59135\tvalid_1's l2: 18.3092\n",
      "[31]\ttraining's l2: 8.41656\tvalid_1's l2: 18.1341\n",
      "[32]\ttraining's l2: 8.20673\tvalid_1's l2: 17.9203\n",
      "[33]\ttraining's l2: 8.04263\tvalid_1's l2: 17.6532\n",
      "[34]\ttraining's l2: 7.84344\tvalid_1's l2: 17.4728\n",
      "[35]\ttraining's l2: 7.68917\tvalid_1's l2: 17.3265\n",
      "[36]\ttraining's l2: 7.54926\tvalid_1's l2: 17.1021\n",
      "[37]\ttraining's l2: 7.41932\tvalid_1's l2: 16.8883\n",
      "[38]\ttraining's l2: 7.13778\tvalid_1's l2: 16.3934\n",
      "[39]\ttraining's l2: 6.96537\tvalid_1's l2: 16.1275\n",
      "[40]\ttraining's l2: 6.81617\tvalid_1's l2: 15.8271\n",
      "[41]\ttraining's l2: 6.71135\tvalid_1's l2: 15.7753\n",
      "[42]\ttraining's l2: 6.51395\tvalid_1's l2: 15.5742\n",
      "[43]\ttraining's l2: 6.30581\tvalid_1's l2: 15.2656\n",
      "[44]\ttraining's l2: 6.19358\tvalid_1's l2: 15.0234\n",
      "[45]\ttraining's l2: 6.02576\tvalid_1's l2: 14.7816\n",
      "[46]\ttraining's l2: 5.93436\tvalid_1's l2: 14.5994\n",
      "[47]\ttraining's l2: 5.7775\tvalid_1's l2: 14.4134\n",
      "[48]\ttraining's l2: 5.64271\tvalid_1's l2: 14.2327\n",
      "[49]\ttraining's l2: 5.54986\tvalid_1's l2: 14.1729\n",
      "[50]\ttraining's l2: 5.43194\tvalid_1's l2: 14.002\n",
      "[51]\ttraining's l2: 5.35552\tvalid_1's l2: 13.9482\n",
      "[52]\ttraining's l2: 5.26196\tvalid_1's l2: 13.7761\n",
      "[53]\ttraining's l2: 5.16529\tvalid_1's l2: 13.6313\n",
      "[54]\ttraining's l2: 5.10101\tvalid_1's l2: 13.6083\n",
      "[55]\ttraining's l2: 4.99687\tvalid_1's l2: 13.4572\n",
      "[56]\ttraining's l2: 4.9385\tvalid_1's l2: 13.4466\n",
      "[57]\ttraining's l2: 4.87256\tvalid_1's l2: 13.3791\n",
      "[58]\ttraining's l2: 4.79268\tvalid_1's l2: 13.3594\n",
      "[59]\ttraining's l2: 4.70361\tvalid_1's l2: 13.2702\n",
      "[60]\ttraining's l2: 4.60649\tvalid_1's l2: 13.2732\n",
      "[61]\ttraining's l2: 4.53474\tvalid_1's l2: 13.1831\n",
      "[62]\ttraining's l2: 4.46722\tvalid_1's l2: 13.2137\n",
      "[63]\ttraining's l2: 4.40861\tvalid_1's l2: 13.1228\n",
      "[64]\ttraining's l2: 4.33065\tvalid_1's l2: 13.0722\n",
      "[65]\ttraining's l2: 4.28329\tvalid_1's l2: 13.0453\n",
      "[66]\ttraining's l2: 4.22533\tvalid_1's l2: 12.9894\n",
      "[67]\ttraining's l2: 4.16129\tvalid_1's l2: 12.9157\n",
      "[68]\ttraining's l2: 4.11249\tvalid_1's l2: 12.8275\n",
      "[69]\ttraining's l2: 4.05928\tvalid_1's l2: 12.8476\n",
      "[70]\ttraining's l2: 3.99545\tvalid_1's l2: 12.7905\n",
      "[71]\ttraining's l2: 3.9478\tvalid_1's l2: 12.7918\n",
      "[72]\ttraining's l2: 3.88891\tvalid_1's l2: 12.7728\n",
      "[73]\ttraining's l2: 3.83481\tvalid_1's l2: 12.6747\n",
      "[74]\ttraining's l2: 3.76659\tvalid_1's l2: 12.6238\n",
      "[75]\ttraining's l2: 3.70881\tvalid_1's l2: 12.5383\n",
      "[76]\ttraining's l2: 3.6696\tvalid_1's l2: 12.5059\n",
      "[77]\ttraining's l2: 3.62081\tvalid_1's l2: 12.3965\n",
      "[78]\ttraining's l2: 3.56777\tvalid_1's l2: 12.3613\n",
      "[79]\ttraining's l2: 3.51939\tvalid_1's l2: 12.2809\n",
      "[80]\ttraining's l2: 3.48122\tvalid_1's l2: 12.3054\n",
      "[81]\ttraining's l2: 3.43199\tvalid_1's l2: 12.2774\n",
      "[82]\ttraining's l2: 3.3822\tvalid_1's l2: 12.2111\n",
      "[83]\ttraining's l2: 3.34461\tvalid_1's l2: 12.13\n",
      "[84]\ttraining's l2: 3.30331\tvalid_1's l2: 12.0388\n",
      "[85]\ttraining's l2: 3.2538\tvalid_1's l2: 11.9926\n",
      "[86]\ttraining's l2: 3.21641\tvalid_1's l2: 11.9253\n",
      "[87]\ttraining's l2: 3.17458\tvalid_1's l2: 11.9257\n",
      "[88]\ttraining's l2: 3.13302\tvalid_1's l2: 11.9789\n",
      "[89]\ttraining's l2: 3.07811\tvalid_1's l2: 11.9504\n",
      "[90]\ttraining's l2: 3.04146\tvalid_1's l2: 11.9131\n",
      "[91]\ttraining's l2: 3.01296\tvalid_1's l2: 11.885\n",
      "[92]\ttraining's l2: 2.9859\tvalid_1's l2: 11.9164\n",
      "[93]\ttraining's l2: 2.91699\tvalid_1's l2: 11.912\n",
      "[94]\ttraining's l2: 2.88682\tvalid_1's l2: 11.8444\n",
      "[95]\ttraining's l2: 2.85637\tvalid_1's l2: 11.8605\n",
      "[96]\ttraining's l2: 2.83374\tvalid_1's l2: 11.9056\n",
      "[97]\ttraining's l2: 2.81176\tvalid_1's l2: 11.8736\n",
      "[98]\ttraining's l2: 2.77181\tvalid_1's l2: 11.8267\n",
      "[99]\ttraining's l2: 2.7455\tvalid_1's l2: 11.8351\n",
      "[100]\ttraining's l2: 2.71144\tvalid_1's l2: 11.883\n",
      "[101]\ttraining's l2: 2.68437\tvalid_1's l2: 11.8233\n",
      "[102]\ttraining's l2: 2.64959\tvalid_1's l2: 11.8097\n",
      "[103]\ttraining's l2: 2.62713\tvalid_1's l2: 11.7718\n",
      "[104]\ttraining's l2: 2.6101\tvalid_1's l2: 11.7945\n",
      "[105]\ttraining's l2: 2.57721\tvalid_1's l2: 11.7992\n",
      "[106]\ttraining's l2: 2.54666\tvalid_1's l2: 11.8006\n",
      "[107]\ttraining's l2: 2.52526\tvalid_1's l2: 11.7136\n",
      "[108]\ttraining's l2: 2.50946\tvalid_1's l2: 11.7494\n",
      "[109]\ttraining's l2: 2.46956\tvalid_1's l2: 11.7332\n",
      "[110]\ttraining's l2: 2.43632\tvalid_1's l2: 11.7708\n",
      "[111]\ttraining's l2: 2.41287\tvalid_1's l2: 11.7571\n",
      "[112]\ttraining's l2: 2.38114\tvalid_1's l2: 11.7056\n",
      "[113]\ttraining's l2: 2.35889\tvalid_1's l2: 11.7108\n",
      "[114]\ttraining's l2: 2.33841\tvalid_1's l2: 11.669\n",
      "[115]\ttraining's l2: 2.32124\tvalid_1's l2: 11.6862\n",
      "[116]\ttraining's l2: 2.30048\tvalid_1's l2: 11.6979\n",
      "[117]\ttraining's l2: 2.2697\tvalid_1's l2: 11.7508\n",
      "[118]\ttraining's l2: 2.24234\tvalid_1's l2: 11.7627\n",
      "[119]\ttraining's l2: 2.22412\tvalid_1's l2: 11.7572\n",
      "[120]\ttraining's l2: 2.19988\tvalid_1's l2: 11.7937\n",
      "[121]\ttraining's l2: 2.17484\tvalid_1's l2: 11.7916\n",
      "[122]\ttraining's l2: 2.14742\tvalid_1's l2: 11.7976\n",
      "[123]\ttraining's l2: 2.12719\tvalid_1's l2: 11.8\n",
      "[124]\ttraining's l2: 2.10977\tvalid_1's l2: 11.8285\n",
      "[125]\ttraining's l2: 2.08206\tvalid_1's l2: 11.8161\n",
      "[126]\ttraining's l2: 2.05198\tvalid_1's l2: 11.7853\n",
      "[127]\ttraining's l2: 2.03131\tvalid_1's l2: 11.7525\n",
      "[128]\ttraining's l2: 2.01009\tvalid_1's l2: 11.7302\n",
      "[129]\ttraining's l2: 1.99192\tvalid_1's l2: 11.6837\n",
      "[130]\ttraining's l2: 1.96554\tvalid_1's l2: 11.7403\n",
      "[131]\ttraining's l2: 1.93765\tvalid_1's l2: 11.7332\n",
      "[132]\ttraining's l2: 1.9221\tvalid_1's l2: 11.7672\n",
      "[133]\ttraining's l2: 1.89926\tvalid_1's l2: 11.8019\n",
      "[134]\ttraining's l2: 1.88161\tvalid_1's l2: 11.8096\n",
      "[135]\ttraining's l2: 1.86775\tvalid_1's l2: 11.8094\n",
      "[136]\ttraining's l2: 1.84177\tvalid_1's l2: 11.7586\n",
      "[137]\ttraining's l2: 1.82213\tvalid_1's l2: 11.756\n",
      "[138]\ttraining's l2: 1.79946\tvalid_1's l2: 11.7842\n",
      "[139]\ttraining's l2: 1.78123\tvalid_1's l2: 11.8317\n",
      "[140]\ttraining's l2: 1.75655\tvalid_1's l2: 11.7524\n",
      "[141]\ttraining's l2: 1.7451\tvalid_1's l2: 11.7336\n",
      "[142]\ttraining's l2: 1.71831\tvalid_1's l2: 11.7445\n",
      "[143]\ttraining's l2: 1.70719\tvalid_1's l2: 11.7447\n",
      "[144]\ttraining's l2: 1.68873\tvalid_1's l2: 11.745\n",
      "[145]\ttraining's l2: 1.67656\tvalid_1's l2: 11.7502\n",
      "[146]\ttraining's l2: 1.66666\tvalid_1's l2: 11.7466\n",
      "[147]\ttraining's l2: 1.65227\tvalid_1's l2: 11.7723\n",
      "[148]\ttraining's l2: 1.63403\tvalid_1's l2: 11.7868\n",
      "[149]\ttraining's l2: 1.62064\tvalid_1's l2: 11.7475\n",
      "[150]\ttraining's l2: 1.60347\tvalid_1's l2: 11.7287\n",
      "[151]\ttraining's l2: 1.59536\tvalid_1's l2: 11.7078\n",
      "[152]\ttraining's l2: 1.58595\tvalid_1's l2: 11.7133\n",
      "[153]\ttraining's l2: 1.56929\tvalid_1's l2: 11.7037\n",
      "[154]\ttraining's l2: 1.55437\tvalid_1's l2: 11.7354\n",
      "[155]\ttraining's l2: 1.54326\tvalid_1's l2: 11.7349\n",
      "[156]\ttraining's l2: 1.53476\tvalid_1's l2: 11.7592\n",
      "[157]\ttraining's l2: 1.51571\tvalid_1's l2: 11.719\n",
      "[158]\ttraining's l2: 1.50121\tvalid_1's l2: 11.7226\n",
      "[159]\ttraining's l2: 1.48533\tvalid_1's l2: 11.7247\n",
      "[160]\ttraining's l2: 1.4762\tvalid_1's l2: 11.7031\n",
      "[161]\ttraining's l2: 1.46436\tvalid_1's l2: 11.7113\n",
      "[162]\ttraining's l2: 1.4469\tvalid_1's l2: 11.7089\n",
      "[163]\ttraining's l2: 1.43703\tvalid_1's l2: 11.6987\n",
      "[164]\ttraining's l2: 1.4238\tvalid_1's l2: 11.711\n",
      "[165]\ttraining's l2: 1.41397\tvalid_1's l2: 11.693\n",
      "[166]\ttraining's l2: 1.40353\tvalid_1's l2: 11.6759\n",
      "[167]\ttraining's l2: 1.39612\tvalid_1's l2: 11.6338\n",
      "[168]\ttraining's l2: 1.38258\tvalid_1's l2: 11.6068\n",
      "[169]\ttraining's l2: 1.36999\tvalid_1's l2: 11.634\n",
      "[170]\ttraining's l2: 1.36116\tvalid_1's l2: 11.6105\n",
      "[171]\ttraining's l2: 1.35143\tvalid_1's l2: 11.6638\n",
      "[172]\ttraining's l2: 1.33927\tvalid_1's l2: 11.6948\n",
      "[173]\ttraining's l2: 1.32392\tvalid_1's l2: 11.6919\n",
      "[174]\ttraining's l2: 1.31048\tvalid_1's l2: 11.702\n",
      "[175]\ttraining's l2: 1.30198\tvalid_1's l2: 11.7347\n",
      "[176]\ttraining's l2: 1.29063\tvalid_1's l2: 11.7529\n",
      "[177]\ttraining's l2: 1.27788\tvalid_1's l2: 11.7796\n",
      "[178]\ttraining's l2: 1.26535\tvalid_1's l2: 11.8258\n",
      "[179]\ttraining's l2: 1.25471\tvalid_1's l2: 11.8474\n",
      "[180]\ttraining's l2: 1.24122\tvalid_1's l2: 11.8143\n",
      "[181]\ttraining's l2: 1.22678\tvalid_1's l2: 11.7998\n",
      "[182]\ttraining's l2: 1.21243\tvalid_1's l2: 11.8314\n",
      "[183]\ttraining's l2: 1.20707\tvalid_1's l2: 11.8054\n",
      "[184]\ttraining's l2: 1.19913\tvalid_1's l2: 11.7948\n",
      "[185]\ttraining's l2: 1.19155\tvalid_1's l2: 11.7942\n",
      "[186]\ttraining's l2: 1.18122\tvalid_1's l2: 11.8011\n",
      "[187]\ttraining's l2: 1.17059\tvalid_1's l2: 11.8125\n",
      "[188]\ttraining's l2: 1.1664\tvalid_1's l2: 11.7879\n",
      "[189]\ttraining's l2: 1.15495\tvalid_1's l2: 11.7746\n",
      "[190]\ttraining's l2: 1.14483\tvalid_1's l2: 11.8025\n",
      "[191]\ttraining's l2: 1.13231\tvalid_1's l2: 11.8074\n",
      "[192]\ttraining's l2: 1.12523\tvalid_1's l2: 11.7855\n",
      "[193]\ttraining's l2: 1.1165\tvalid_1's l2: 11.8105\n",
      "[194]\ttraining's l2: 1.10914\tvalid_1's l2: 11.8179\n",
      "[195]\ttraining's l2: 1.09824\tvalid_1's l2: 11.841\n",
      "[196]\ttraining's l2: 1.08943\tvalid_1's l2: 11.8288\n",
      "[197]\ttraining's l2: 1.08095\tvalid_1's l2: 11.8434\n",
      "[198]\ttraining's l2: 1.07505\tvalid_1's l2: 11.8204\n",
      "[199]\ttraining's l2: 1.06708\tvalid_1's l2: 11.8387\n",
      "[200]\ttraining's l2: 1.06272\tvalid_1's l2: 11.8313\n",
      "[201]\ttraining's l2: 1.05414\tvalid_1's l2: 11.8562\n",
      "[202]\ttraining's l2: 1.04676\tvalid_1's l2: 11.8716\n",
      "[203]\ttraining's l2: 1.0388\tvalid_1's l2: 11.8693\n",
      "[204]\ttraining's l2: 1.03285\tvalid_1's l2: 11.8652\n",
      "[205]\ttraining's l2: 1.02319\tvalid_1's l2: 11.8691\n",
      "[206]\ttraining's l2: 1.01479\tvalid_1's l2: 11.8833\n",
      "[207]\ttraining's l2: 1.0069\tvalid_1's l2: 11.9021\n",
      "[208]\ttraining's l2: 0.993145\tvalid_1's l2: 11.9378\n",
      "[209]\ttraining's l2: 0.989484\tvalid_1's l2: 11.9197\n",
      "[210]\ttraining's l2: 0.981744\tvalid_1's l2: 11.9284\n",
      "[211]\ttraining's l2: 0.972299\tvalid_1's l2: 11.9606\n",
      "[212]\ttraining's l2: 0.965921\tvalid_1's l2: 11.939\n",
      "[213]\ttraining's l2: 0.961002\tvalid_1's l2: 11.9192\n",
      "[214]\ttraining's l2: 0.953549\tvalid_1's l2: 11.9246\n",
      "[215]\ttraining's l2: 0.943635\tvalid_1's l2: 11.8956\n",
      "[216]\ttraining's l2: 0.937478\tvalid_1's l2: 11.9179\n",
      "[217]\ttraining's l2: 0.930992\tvalid_1's l2: 11.9167\n",
      "[218]\ttraining's l2: 0.92456\tvalid_1's l2: 11.9054\n",
      "[219]\ttraining's l2: 0.916458\tvalid_1's l2: 11.9113\n",
      "[220]\ttraining's l2: 0.908697\tvalid_1's l2: 11.898\n",
      "[221]\ttraining's l2: 0.901495\tvalid_1's l2: 11.9071\n",
      "[222]\ttraining's l2: 0.894496\tvalid_1's l2: 11.8839\n",
      "[223]\ttraining's l2: 0.888782\tvalid_1's l2: 11.9068\n",
      "[224]\ttraining's l2: 0.882596\tvalid_1's l2: 11.9042\n",
      "[225]\ttraining's l2: 0.874016\tvalid_1's l2: 11.8986\n",
      "[226]\ttraining's l2: 0.866939\tvalid_1's l2: 11.9172\n",
      "[227]\ttraining's l2: 0.860479\tvalid_1's l2: 11.9279\n",
      "[228]\ttraining's l2: 0.851897\tvalid_1's l2: 11.963\n",
      "[229]\ttraining's l2: 0.84661\tvalid_1's l2: 11.9393\n",
      "[230]\ttraining's l2: 0.841362\tvalid_1's l2: 11.9443\n",
      "[231]\ttraining's l2: 0.835161\tvalid_1's l2: 11.9407\n",
      "[232]\ttraining's l2: 0.829225\tvalid_1's l2: 11.9497\n",
      "[233]\ttraining's l2: 0.819646\tvalid_1's l2: 11.9572\n",
      "[234]\ttraining's l2: 0.810461\tvalid_1's l2: 11.9113\n",
      "[235]\ttraining's l2: 0.804503\tvalid_1's l2: 11.9379\n",
      "[236]\ttraining's l2: 0.79891\tvalid_1's l2: 11.9349\n",
      "[237]\ttraining's l2: 0.793344\tvalid_1's l2: 11.9319\n",
      "[238]\ttraining's l2: 0.78707\tvalid_1's l2: 11.9477\n",
      "[239]\ttraining's l2: 0.778178\tvalid_1's l2: 11.9717\n",
      "[240]\ttraining's l2: 0.772857\tvalid_1's l2: 11.9677\n",
      "[241]\ttraining's l2: 0.767183\tvalid_1's l2: 11.9777\n",
      "[242]\ttraining's l2: 0.759516\tvalid_1's l2: 12.0052\n",
      "[243]\ttraining's l2: 0.754769\tvalid_1's l2: 12.0023\n",
      "[244]\ttraining's l2: 0.748414\tvalid_1's l2: 11.9832\n",
      "[245]\ttraining's l2: 0.744061\tvalid_1's l2: 11.9732\n",
      "[246]\ttraining's l2: 0.739212\tvalid_1's l2: 11.99\n",
      "[247]\ttraining's l2: 0.733375\tvalid_1's l2: 12.0085\n",
      "[248]\ttraining's l2: 0.728809\tvalid_1's l2: 12.0078\n",
      "[249]\ttraining's l2: 0.723389\tvalid_1's l2: 12.0101\n",
      "[250]\ttraining's l2: 0.718749\tvalid_1's l2: 12.0147\n",
      "[251]\ttraining's l2: 0.711018\tvalid_1's l2: 11.9778\n",
      "[252]\ttraining's l2: 0.705016\tvalid_1's l2: 11.9742\n",
      "[253]\ttraining's l2: 0.699262\tvalid_1's l2: 11.9855\n",
      "[254]\ttraining's l2: 0.693931\tvalid_1's l2: 11.9506\n",
      "[255]\ttraining's l2: 0.689773\tvalid_1's l2: 11.9724\n",
      "[256]\ttraining's l2: 0.685012\tvalid_1's l2: 11.9693\n",
      "[257]\ttraining's l2: 0.680249\tvalid_1's l2: 11.9708\n",
      "[258]\ttraining's l2: 0.675165\tvalid_1's l2: 11.9878\n",
      "[259]\ttraining's l2: 0.666866\tvalid_1's l2: 12.0042\n",
      "[260]\ttraining's l2: 0.662162\tvalid_1's l2: 11.9937\n",
      "[261]\ttraining's l2: 0.657656\tvalid_1's l2: 12.0009\n",
      "[262]\ttraining's l2: 0.653338\tvalid_1's l2: 11.9983\n",
      "[263]\ttraining's l2: 0.649258\tvalid_1's l2: 12.009\n",
      "[264]\ttraining's l2: 0.645824\tvalid_1's l2: 11.9968\n",
      "[265]\ttraining's l2: 0.639612\tvalid_1's l2: 12.0075\n",
      "[266]\ttraining's l2: 0.636406\tvalid_1's l2: 12.0042\n",
      "[267]\ttraining's l2: 0.630354\tvalid_1's l2: 12.0262\n",
      "[268]\ttraining's l2: 0.62791\tvalid_1's l2: 12.016\n",
      "[269]\ttraining's l2: 0.623697\tvalid_1's l2: 12.0203\n",
      "[270]\ttraining's l2: 0.621128\tvalid_1's l2: 12.017\n",
      "[271]\ttraining's l2: 0.616662\tvalid_1's l2: 12.0134\n",
      "[272]\ttraining's l2: 0.610952\tvalid_1's l2: 11.9957\n",
      "[273]\ttraining's l2: 0.607227\tvalid_1's l2: 11.9771\n",
      "[274]\ttraining's l2: 0.602464\tvalid_1's l2: 11.9938\n",
      "[275]\ttraining's l2: 0.599003\tvalid_1's l2: 11.9999\n",
      "[276]\ttraining's l2: 0.593968\tvalid_1's l2: 11.9859\n",
      "[277]\ttraining's l2: 0.589593\tvalid_1's l2: 11.9997\n",
      "[278]\ttraining's l2: 0.586714\tvalid_1's l2: 12.0021\n",
      "[279]\ttraining's l2: 0.583592\tvalid_1's l2: 12.0202\n",
      "[280]\ttraining's l2: 0.580916\tvalid_1's l2: 12.0165\n",
      "[281]\ttraining's l2: 0.575285\tvalid_1's l2: 11.9958\n",
      "[282]\ttraining's l2: 0.572067\tvalid_1's l2: 11.9771\n",
      "[283]\ttraining's l2: 0.567822\tvalid_1's l2: 11.9906\n",
      "[284]\ttraining's l2: 0.56369\tvalid_1's l2: 12.0068\n",
      "[285]\ttraining's l2: 0.561027\tvalid_1's l2: 12.0054\n",
      "[286]\ttraining's l2: 0.557547\tvalid_1's l2: 11.9753\n",
      "[287]\ttraining's l2: 0.554469\tvalid_1's l2: 11.9919\n",
      "[288]\ttraining's l2: 0.549249\tvalid_1's l2: 12.0102\n",
      "[289]\ttraining's l2: 0.546866\tvalid_1's l2: 12.0047\n",
      "[290]\ttraining's l2: 0.542651\tvalid_1's l2: 12.0202\n",
      "[291]\ttraining's l2: 0.539401\tvalid_1's l2: 12.0086\n",
      "[292]\ttraining's l2: 0.536026\tvalid_1's l2: 12.0201\n",
      "[293]\ttraining's l2: 0.532921\tvalid_1's l2: 12.0251\n",
      "[294]\ttraining's l2: 0.529075\tvalid_1's l2: 12.0356\n",
      "[295]\ttraining's l2: 0.525441\tvalid_1's l2: 12.0606\n",
      "[296]\ttraining's l2: 0.522487\tvalid_1's l2: 12.0574\n",
      "[297]\ttraining's l2: 0.518599\tvalid_1's l2: 12.0613\n",
      "[298]\ttraining's l2: 0.515402\tvalid_1's l2: 12.0469\n",
      "[299]\ttraining's l2: 0.510362\tvalid_1's l2: 12.0835\n",
      "[300]\ttraining's l2: 0.507384\tvalid_1's l2: 12.0855\n",
      "[1]\ttraining's l2: 70.4797\tvalid_1's l2: 81.3825\n",
      "[2]\ttraining's l2: 58.8981\tvalid_1's l2: 68.458\n",
      "[3]\ttraining's l2: 49.6299\tvalid_1's l2: 60.0852\n",
      "[4]\ttraining's l2: 41.9025\tvalid_1's l2: 51.7181\n",
      "[5]\ttraining's l2: 35.501\tvalid_1's l2: 44.4838\n",
      "[6]\ttraining's l2: 30.3483\tvalid_1's l2: 38.4096\n",
      "[7]\ttraining's l2: 25.897\tvalid_1's l2: 33.7657\n",
      "[8]\ttraining's l2: 22.1624\tvalid_1's l2: 30.1007\n",
      "[9]\ttraining's l2: 19.2385\tvalid_1's l2: 26.7063\n",
      "[10]\ttraining's l2: 16.6123\tvalid_1's l2: 23.6869\n",
      "[11]\ttraining's l2: 14.3688\tvalid_1's l2: 22.0768\n",
      "[12]\ttraining's l2: 12.5081\tvalid_1's l2: 20.0705\n",
      "[13]\ttraining's l2: 10.8928\tvalid_1's l2: 18.3935\n",
      "[14]\ttraining's l2: 9.59795\tvalid_1's l2: 17.1302\n",
      "[15]\ttraining's l2: 8.42335\tvalid_1's l2: 15.9328\n",
      "[16]\ttraining's l2: 7.32384\tvalid_1's l2: 14.7532\n",
      "[17]\ttraining's l2: 6.48615\tvalid_1's l2: 14.0169\n",
      "[18]\ttraining's l2: 5.8018\tvalid_1's l2: 13.4367\n",
      "[19]\ttraining's l2: 5.23639\tvalid_1's l2: 12.7929\n",
      "[20]\ttraining's l2: 4.74019\tvalid_1's l2: 12.4056\n",
      "[21]\ttraining's l2: 4.27656\tvalid_1's l2: 12.176\n",
      "[22]\ttraining's l2: 3.89276\tvalid_1's l2: 11.8297\n",
      "[23]\ttraining's l2: 3.52968\tvalid_1's l2: 11.6796\n",
      "[24]\ttraining's l2: 3.20611\tvalid_1's l2: 11.4273\n",
      "[25]\ttraining's l2: 2.92224\tvalid_1's l2: 11.2031\n",
      "[26]\ttraining's l2: 2.665\tvalid_1's l2: 11.0897\n",
      "[27]\ttraining's l2: 2.44782\tvalid_1's l2: 10.9931\n",
      "[28]\ttraining's l2: 2.24185\tvalid_1's l2: 10.9222\n",
      "[29]\ttraining's l2: 2.1035\tvalid_1's l2: 10.9237\n",
      "[30]\ttraining's l2: 1.98777\tvalid_1's l2: 10.9316\n",
      "[31]\ttraining's l2: 1.85187\tvalid_1's l2: 10.8627\n",
      "[32]\ttraining's l2: 1.74893\tvalid_1's l2: 10.8216\n",
      "[33]\ttraining's l2: 1.63563\tvalid_1's l2: 10.742\n",
      "[34]\ttraining's l2: 1.54197\tvalid_1's l2: 10.7413\n",
      "[35]\ttraining's l2: 1.46999\tvalid_1's l2: 10.723\n",
      "[36]\ttraining's l2: 1.38645\tvalid_1's l2: 10.7276\n",
      "[37]\ttraining's l2: 1.33269\tvalid_1's l2: 10.7056\n",
      "[38]\ttraining's l2: 1.26056\tvalid_1's l2: 10.7442\n",
      "[39]\ttraining's l2: 1.2131\tvalid_1's l2: 10.7348\n",
      "[40]\ttraining's l2: 1.15465\tvalid_1's l2: 10.7267\n",
      "[41]\ttraining's l2: 1.09777\tvalid_1's l2: 10.7148\n",
      "[42]\ttraining's l2: 1.04899\tvalid_1's l2: 10.6832\n",
      "[43]\ttraining's l2: 1.00649\tvalid_1's l2: 10.6977\n",
      "[44]\ttraining's l2: 0.967161\tvalid_1's l2: 10.6879\n",
      "[45]\ttraining's l2: 0.931475\tvalid_1's l2: 10.6813\n",
      "[46]\ttraining's l2: 0.903626\tvalid_1's l2: 10.6639\n",
      "[47]\ttraining's l2: 0.870582\tvalid_1's l2: 10.6609\n",
      "[48]\ttraining's l2: 0.849229\tvalid_1's l2: 10.6798\n",
      "[49]\ttraining's l2: 0.826852\tvalid_1's l2: 10.7014\n",
      "[50]\ttraining's l2: 0.809438\tvalid_1's l2: 10.7269\n",
      "[51]\ttraining's l2: 0.79052\tvalid_1's l2: 10.7285\n",
      "[52]\ttraining's l2: 0.772565\tvalid_1's l2: 10.7424\n",
      "[53]\ttraining's l2: 0.757212\tvalid_1's l2: 10.7755\n",
      "[54]\ttraining's l2: 0.741823\tvalid_1's l2: 10.7472\n",
      "[55]\ttraining's l2: 0.72535\tvalid_1's l2: 10.7691\n",
      "[56]\ttraining's l2: 0.708297\tvalid_1's l2: 10.762\n",
      "[57]\ttraining's l2: 0.691713\tvalid_1's l2: 10.7982\n",
      "[58]\ttraining's l2: 0.678352\tvalid_1's l2: 10.8379\n",
      "[59]\ttraining's l2: 0.666211\tvalid_1's l2: 10.8668\n",
      "[60]\ttraining's l2: 0.654134\tvalid_1's l2: 10.895\n",
      "[61]\ttraining's l2: 0.641687\tvalid_1's l2: 10.8736\n",
      "[62]\ttraining's l2: 0.631483\tvalid_1's l2: 10.9009\n",
      "[63]\ttraining's l2: 0.620471\tvalid_1's l2: 10.9175\n",
      "[64]\ttraining's l2: 0.610625\tvalid_1's l2: 10.8917\n",
      "[65]\ttraining's l2: 0.602392\tvalid_1's l2: 10.9145\n",
      "[66]\ttraining's l2: 0.592954\tvalid_1's l2: 10.9401\n",
      "[67]\ttraining's l2: 0.584997\tvalid_1's l2: 10.9527\n",
      "[68]\ttraining's l2: 0.576081\tvalid_1's l2: 10.9502\n",
      "[69]\ttraining's l2: 0.567384\tvalid_1's l2: 10.9844\n",
      "[70]\ttraining's l2: 0.558215\tvalid_1's l2: 10.9672\n",
      "[71]\ttraining's l2: 0.551287\tvalid_1's l2: 10.9789\n",
      "[72]\ttraining's l2: 0.542757\tvalid_1's l2: 10.9845\n",
      "[73]\ttraining's l2: 0.535819\tvalid_1's l2: 10.9865\n",
      "[74]\ttraining's l2: 0.52828\tvalid_1's l2: 11.0159\n",
      "[75]\ttraining's l2: 0.522188\tvalid_1's l2: 10.9976\n",
      "[76]\ttraining's l2: 0.515724\tvalid_1's l2: 11.0324\n",
      "[77]\ttraining's l2: 0.509055\tvalid_1's l2: 11.0635\n",
      "[78]\ttraining's l2: 0.502526\tvalid_1's l2: 11.0377\n",
      "[79]\ttraining's l2: 0.497149\tvalid_1's l2: 11.0465\n",
      "[80]\ttraining's l2: 0.491606\tvalid_1's l2: 11.068\n",
      "[81]\ttraining's l2: 0.485797\tvalid_1's l2: 11.0404\n",
      "[82]\ttraining's l2: 0.480652\tvalid_1's l2: 11.0512\n",
      "[83]\ttraining's l2: 0.47445\tvalid_1's l2: 11.0709\n",
      "[84]\ttraining's l2: 0.46953\tvalid_1's l2: 11.093\n",
      "[85]\ttraining's l2: 0.464273\tvalid_1's l2: 11.109\n",
      "[86]\ttraining's l2: 0.459448\tvalid_1's l2: 11.0994\n",
      "[87]\ttraining's l2: 0.454901\tvalid_1's l2: 11.1219\n",
      "[88]\ttraining's l2: 0.449984\tvalid_1's l2: 11.134\n",
      "[89]\ttraining's l2: 0.444942\tvalid_1's l2: 11.1532\n",
      "[90]\ttraining's l2: 0.439996\tvalid_1's l2: 11.1739\n",
      "[91]\ttraining's l2: 0.435627\tvalid_1's l2: 11.1894\n",
      "[92]\ttraining's l2: 0.431317\tvalid_1's l2: 11.1741\n",
      "[93]\ttraining's l2: 0.42654\tvalid_1's l2: 11.1494\n",
      "[94]\ttraining's l2: 0.422311\tvalid_1's l2: 11.1575\n",
      "[95]\ttraining's l2: 0.417741\tvalid_1's l2: 11.1896\n",
      "[96]\ttraining's l2: 0.413598\tvalid_1's l2: 11.1626\n",
      "[97]\ttraining's l2: 0.409354\tvalid_1's l2: 11.1791\n",
      "[98]\ttraining's l2: 0.405035\tvalid_1's l2: 11.1999\n",
      "[99]\ttraining's l2: 0.400756\tvalid_1's l2: 11.2047\n",
      "[100]\ttraining's l2: 0.396925\tvalid_1's l2: 11.236\n",
      "[101]\ttraining's l2: 0.392962\tvalid_1's l2: 11.2466\n",
      "[102]\ttraining's l2: 0.38897\tvalid_1's l2: 11.233\n",
      "[103]\ttraining's l2: 0.384974\tvalid_1's l2: 11.25\n",
      "[104]\ttraining's l2: 0.38105\tvalid_1's l2: 11.2642\n",
      "[105]\ttraining's l2: 0.377248\tvalid_1's l2: 11.2884\n",
      "[106]\ttraining's l2: 0.373831\tvalid_1's l2: 11.3026\n",
      "[107]\ttraining's l2: 0.370549\tvalid_1's l2: 11.2903\n",
      "[108]\ttraining's l2: 0.367205\tvalid_1's l2: 11.2952\n",
      "[109]\ttraining's l2: 0.363756\tvalid_1's l2: 11.291\n",
      "[110]\ttraining's l2: 0.360826\tvalid_1's l2: 11.2962\n",
      "[111]\ttraining's l2: 0.357456\tvalid_1's l2: 11.3242\n",
      "[112]\ttraining's l2: 0.354298\tvalid_1's l2: 11.3362\n",
      "[113]\ttraining's l2: 0.350658\tvalid_1's l2: 11.3428\n",
      "[114]\ttraining's l2: 0.347487\tvalid_1's l2: 11.3178\n",
      "[115]\ttraining's l2: 0.344141\tvalid_1's l2: 11.3406\n",
      "[116]\ttraining's l2: 0.341231\tvalid_1's l2: 11.3299\n",
      "[117]\ttraining's l2: 0.338441\tvalid_1's l2: 11.3294\n",
      "[118]\ttraining's l2: 0.335417\tvalid_1's l2: 11.3392\n",
      "[119]\ttraining's l2: 0.332532\tvalid_1's l2: 11.3514\n",
      "[120]\ttraining's l2: 0.329464\tvalid_1's l2: 11.3553\n",
      "[121]\ttraining's l2: 0.326685\tvalid_1's l2: 11.3538\n",
      "[122]\ttraining's l2: 0.323487\tvalid_1's l2: 11.3828\n",
      "[123]\ttraining's l2: 0.320459\tvalid_1's l2: 11.3901\n",
      "[124]\ttraining's l2: 0.317603\tvalid_1's l2: 11.3969\n",
      "[125]\ttraining's l2: 0.314864\tvalid_1's l2: 11.3985\n",
      "[126]\ttraining's l2: 0.311905\tvalid_1's l2: 11.3803\n",
      "[127]\ttraining's l2: 0.309022\tvalid_1's l2: 11.3875\n",
      "[128]\ttraining's l2: 0.306415\tvalid_1's l2: 11.4007\n",
      "[129]\ttraining's l2: 0.303627\tvalid_1's l2: 11.3792\n",
      "[130]\ttraining's l2: 0.301053\tvalid_1's l2: 11.3953\n",
      "[131]\ttraining's l2: 0.298597\tvalid_1's l2: 11.3831\n",
      "[132]\ttraining's l2: 0.295992\tvalid_1's l2: 11.4015\n",
      "[133]\ttraining's l2: 0.293323\tvalid_1's l2: 11.4036\n",
      "[134]\ttraining's l2: 0.290591\tvalid_1's l2: 11.393\n",
      "[135]\ttraining's l2: 0.288064\tvalid_1's l2: 11.4176\n",
      "[136]\ttraining's l2: 0.285675\tvalid_1's l2: 11.4261\n",
      "[137]\ttraining's l2: 0.283341\tvalid_1's l2: 11.405\n",
      "[138]\ttraining's l2: 0.281049\tvalid_1's l2: 11.4133\n",
      "[139]\ttraining's l2: 0.278364\tvalid_1's l2: 11.4182\n",
      "[140]\ttraining's l2: 0.275776\tvalid_1's l2: 11.4199\n",
      "[141]\ttraining's l2: 0.273312\tvalid_1's l2: 11.4283\n",
      "[142]\ttraining's l2: 0.27107\tvalid_1's l2: 11.4369\n",
      "[143]\ttraining's l2: 0.268684\tvalid_1's l2: 11.4477\n",
      "[144]\ttraining's l2: 0.26636\tvalid_1's l2: 11.4371\n",
      "[145]\ttraining's l2: 0.263937\tvalid_1's l2: 11.4457\n",
      "[146]\ttraining's l2: 0.261868\tvalid_1's l2: 11.4251\n",
      "[147]\ttraining's l2: 0.259721\tvalid_1's l2: 11.4355\n",
      "[148]\ttraining's l2: 0.257408\tvalid_1's l2: 11.4535\n",
      "[149]\ttraining's l2: 0.255118\tvalid_1's l2: 11.4395\n",
      "[150]\ttraining's l2: 0.252943\tvalid_1's l2: 11.4593\n",
      "[151]\ttraining's l2: 0.250774\tvalid_1's l2: 11.475\n",
      "[152]\ttraining's l2: 0.248745\tvalid_1's l2: 11.4653\n",
      "[153]\ttraining's l2: 0.246626\tvalid_1's l2: 11.4734\n",
      "[154]\ttraining's l2: 0.244325\tvalid_1's l2: 11.4543\n",
      "[155]\ttraining's l2: 0.242141\tvalid_1's l2: 11.4649\n",
      "[156]\ttraining's l2: 0.240175\tvalid_1's l2: 11.4799\n",
      "[157]\ttraining's l2: 0.238234\tvalid_1's l2: 11.4862\n",
      "[158]\ttraining's l2: 0.236256\tvalid_1's l2: 11.4737\n",
      "[159]\ttraining's l2: 0.234394\tvalid_1's l2: 11.478\n",
      "[160]\ttraining's l2: 0.232347\tvalid_1's l2: 11.4918\n",
      "[161]\ttraining's l2: 0.230582\tvalid_1's l2: 11.4742\n",
      "[162]\ttraining's l2: 0.228537\tvalid_1's l2: 11.483\n",
      "[163]\ttraining's l2: 0.22666\tvalid_1's l2: 11.4742\n",
      "[164]\ttraining's l2: 0.224791\tvalid_1's l2: 11.4791\n",
      "[165]\ttraining's l2: 0.223025\tvalid_1's l2: 11.4883\n",
      "[166]\ttraining's l2: 0.221192\tvalid_1's l2: 11.4823\n",
      "[167]\ttraining's l2: 0.219473\tvalid_1's l2: 11.4879\n",
      "[168]\ttraining's l2: 0.21782\tvalid_1's l2: 11.4976\n",
      "[169]\ttraining's l2: 0.215975\tvalid_1's l2: 11.5043\n",
      "[170]\ttraining's l2: 0.21421\tvalid_1's l2: 11.4881\n",
      "[171]\ttraining's l2: 0.212257\tvalid_1's l2: 11.4707\n",
      "[172]\ttraining's l2: 0.210502\tvalid_1's l2: 11.4894\n",
      "[173]\ttraining's l2: 0.208633\tvalid_1's l2: 11.4957\n",
      "[174]\ttraining's l2: 0.206865\tvalid_1's l2: 11.5005\n",
      "[175]\ttraining's l2: 0.205127\tvalid_1's l2: 11.5056\n",
      "[176]\ttraining's l2: 0.20342\tvalid_1's l2: 11.5034\n",
      "[177]\ttraining's l2: 0.20198\tvalid_1's l2: 11.5061\n",
      "[178]\ttraining's l2: 0.200178\tvalid_1's l2: 11.5167\n",
      "[179]\ttraining's l2: 0.198676\tvalid_1's l2: 11.5127\n",
      "[180]\ttraining's l2: 0.197052\tvalid_1's l2: 11.5138\n",
      "[181]\ttraining's l2: 0.195574\tvalid_1's l2: 11.4959\n",
      "[182]\ttraining's l2: 0.194027\tvalid_1's l2: 11.5087\n",
      "[183]\ttraining's l2: 0.192475\tvalid_1's l2: 11.513\n",
      "[184]\ttraining's l2: 0.190784\tvalid_1's l2: 11.5116\n",
      "[185]\ttraining's l2: 0.189189\tvalid_1's l2: 11.5236\n",
      "[186]\ttraining's l2: 0.187776\tvalid_1's l2: 11.5163\n",
      "[187]\ttraining's l2: 0.186308\tvalid_1's l2: 11.5242\n",
      "[188]\ttraining's l2: 0.184883\tvalid_1's l2: 11.532\n",
      "[189]\ttraining's l2: 0.183367\tvalid_1's l2: 11.5171\n",
      "[190]\ttraining's l2: 0.18198\tvalid_1's l2: 11.5286\n",
      "[191]\ttraining's l2: 0.180599\tvalid_1's l2: 11.5351\n",
      "[192]\ttraining's l2: 0.179209\tvalid_1's l2: 11.5247\n",
      "[193]\ttraining's l2: 0.177702\tvalid_1's l2: 11.5378\n",
      "[194]\ttraining's l2: 0.17633\tvalid_1's l2: 11.5408\n",
      "[195]\ttraining's l2: 0.174977\tvalid_1's l2: 11.5353\n",
      "[196]\ttraining's l2: 0.173638\tvalid_1's l2: 11.5227\n",
      "[197]\ttraining's l2: 0.172248\tvalid_1's l2: 11.5372\n",
      "[198]\ttraining's l2: 0.170938\tvalid_1's l2: 11.5228\n",
      "[199]\ttraining's l2: 0.169554\tvalid_1's l2: 11.533\n",
      "[200]\ttraining's l2: 0.16815\tvalid_1's l2: 11.5457\n",
      "[201]\ttraining's l2: 0.166844\tvalid_1's l2: 11.5537\n",
      "[202]\ttraining's l2: 0.165544\tvalid_1's l2: 11.5629\n",
      "[203]\ttraining's l2: 0.164241\tvalid_1's l2: 11.5605\n",
      "[204]\ttraining's l2: 0.162904\tvalid_1's l2: 11.5632\n",
      "[205]\ttraining's l2: 0.161545\tvalid_1's l2: 11.5708\n",
      "[206]\ttraining's l2: 0.160355\tvalid_1's l2: 11.5809\n",
      "[207]\ttraining's l2: 0.159133\tvalid_1's l2: 11.58\n",
      "[208]\ttraining's l2: 0.157922\tvalid_1's l2: 11.5871\n",
      "[209]\ttraining's l2: 0.15676\tvalid_1's l2: 11.5829\n",
      "[210]\ttraining's l2: 0.155517\tvalid_1's l2: 11.5797\n",
      "[211]\ttraining's l2: 0.154307\tvalid_1's l2: 11.5919\n",
      "[212]\ttraining's l2: 0.153175\tvalid_1's l2: 11.5779\n",
      "[213]\ttraining's l2: 0.15176\tvalid_1's l2: 11.5908\n",
      "[214]\ttraining's l2: 0.150477\tvalid_1's l2: 11.5958\n",
      "[215]\ttraining's l2: 0.149288\tvalid_1's l2: 11.59\n",
      "[216]\ttraining's l2: 0.148124\tvalid_1's l2: 11.5999\n",
      "[217]\ttraining's l2: 0.147001\tvalid_1's l2: 11.6081\n",
      "[218]\ttraining's l2: 0.145855\tvalid_1's l2: 11.5936\n",
      "[219]\ttraining's l2: 0.144694\tvalid_1's l2: 11.6071\n",
      "[220]\ttraining's l2: 0.143573\tvalid_1's l2: 11.6033\n",
      "[221]\ttraining's l2: 0.142331\tvalid_1's l2: 11.6053\n",
      "[222]\ttraining's l2: 0.14122\tvalid_1's l2: 11.5966\n",
      "[223]\ttraining's l2: 0.140149\tvalid_1's l2: 11.5878\n",
      "[224]\ttraining's l2: 0.139035\tvalid_1's l2: 11.5974\n",
      "[225]\ttraining's l2: 0.13809\tvalid_1's l2: 11.5994\n",
      "[226]\ttraining's l2: 0.136944\tvalid_1's l2: 11.6101\n",
      "[227]\ttraining's l2: 0.135801\tvalid_1's l2: 11.5931\n",
      "[228]\ttraining's l2: 0.134795\tvalid_1's l2: 11.598\n",
      "[229]\ttraining's l2: 0.133741\tvalid_1's l2: 11.6058\n",
      "[230]\ttraining's l2: 0.13272\tvalid_1's l2: 11.5968\n",
      "[231]\ttraining's l2: 0.131684\tvalid_1's l2: 11.5814\n",
      "[232]\ttraining's l2: 0.130603\tvalid_1's l2: 11.5924\n",
      "[233]\ttraining's l2: 0.12967\tvalid_1's l2: 11.6004\n",
      "[234]\ttraining's l2: 0.128697\tvalid_1's l2: 11.6078\n",
      "[235]\ttraining's l2: 0.127662\tvalid_1's l2: 11.6134\n",
      "[236]\ttraining's l2: 0.126683\tvalid_1's l2: 11.6012\n",
      "[237]\ttraining's l2: 0.125781\tvalid_1's l2: 11.6003\n",
      "[238]\ttraining's l2: 0.12483\tvalid_1's l2: 11.6052\n",
      "[239]\ttraining's l2: 0.123912\tvalid_1's l2: 11.6093\n",
      "[240]\ttraining's l2: 0.122948\tvalid_1's l2: 11.6111\n",
      "[241]\ttraining's l2: 0.122009\tvalid_1's l2: 11.6054\n",
      "[242]\ttraining's l2: 0.12111\tvalid_1's l2: 11.6095\n",
      "[243]\ttraining's l2: 0.120193\tvalid_1's l2: 11.6232\n",
      "[244]\ttraining's l2: 0.119189\tvalid_1's l2: 11.6178\n",
      "[245]\ttraining's l2: 0.118271\tvalid_1's l2: 11.6256\n",
      "[246]\ttraining's l2: 0.11738\tvalid_1's l2: 11.6309\n",
      "[247]\ttraining's l2: 0.116442\tvalid_1's l2: 11.618\n",
      "[248]\ttraining's l2: 0.115556\tvalid_1's l2: 11.6222\n",
      "[249]\ttraining's l2: 0.114652\tvalid_1's l2: 11.6155\n",
      "[250]\ttraining's l2: 0.113722\tvalid_1's l2: 11.6225\n",
      "[251]\ttraining's l2: 0.112897\tvalid_1's l2: 11.6204\n",
      "[252]\ttraining's l2: 0.112024\tvalid_1's l2: 11.63\n",
      "[253]\ttraining's l2: 0.111189\tvalid_1's l2: 11.6369\n",
      "[254]\ttraining's l2: 0.110315\tvalid_1's l2: 11.6492\n",
      "[255]\ttraining's l2: 0.109505\tvalid_1's l2: 11.653\n",
      "[256]\ttraining's l2: 0.108626\tvalid_1's l2: 11.6587\n",
      "[257]\ttraining's l2: 0.107836\tvalid_1's l2: 11.6488\n",
      "[258]\ttraining's l2: 0.106997\tvalid_1's l2: 11.6473\n",
      "[259]\ttraining's l2: 0.10622\tvalid_1's l2: 11.643\n",
      "[260]\ttraining's l2: 0.105427\tvalid_1's l2: 11.6549\n",
      "[261]\ttraining's l2: 0.104665\tvalid_1's l2: 11.6621\n",
      "[262]\ttraining's l2: 0.103899\tvalid_1's l2: 11.6647\n",
      "[263]\ttraining's l2: 0.103081\tvalid_1's l2: 11.6725\n",
      "[264]\ttraining's l2: 0.102211\tvalid_1's l2: 11.6743\n",
      "[265]\ttraining's l2: 0.101398\tvalid_1's l2: 11.679\n",
      "[266]\ttraining's l2: 0.100684\tvalid_1's l2: 11.6681\n",
      "[267]\ttraining's l2: 0.0999516\tvalid_1's l2: 11.6782\n",
      "[268]\ttraining's l2: 0.099187\tvalid_1's l2: 11.6734\n",
      "[269]\ttraining's l2: 0.0983794\tvalid_1's l2: 11.6793\n",
      "[270]\ttraining's l2: 0.097628\tvalid_1's l2: 11.6777\n",
      "[271]\ttraining's l2: 0.0968805\tvalid_1's l2: 11.6903\n",
      "[272]\ttraining's l2: 0.0961444\tvalid_1's l2: 11.6914\n",
      "[273]\ttraining's l2: 0.0954992\tvalid_1's l2: 11.6917\n",
      "[274]\ttraining's l2: 0.0948171\tvalid_1's l2: 11.6815\n",
      "[275]\ttraining's l2: 0.0941046\tvalid_1's l2: 11.6875\n",
      "[276]\ttraining's l2: 0.0933947\tvalid_1's l2: 11.6974\n",
      "[277]\ttraining's l2: 0.0926291\tvalid_1's l2: 11.6968\n",
      "[278]\ttraining's l2: 0.0919004\tvalid_1's l2: 11.6886\n",
      "[279]\ttraining's l2: 0.0912444\tvalid_1's l2: 11.6864\n",
      "[280]\ttraining's l2: 0.0905687\tvalid_1's l2: 11.6965\n",
      "[281]\ttraining's l2: 0.0898592\tvalid_1's l2: 11.7022\n",
      "[282]\ttraining's l2: 0.0891298\tvalid_1's l2: 11.6906\n",
      "[283]\ttraining's l2: 0.0884688\tvalid_1's l2: 11.6957\n",
      "[284]\ttraining's l2: 0.0878324\tvalid_1's l2: 11.6905\n",
      "[285]\ttraining's l2: 0.0872121\tvalid_1's l2: 11.6978\n",
      "[286]\ttraining's l2: 0.0866024\tvalid_1's l2: 11.7055\n",
      "[287]\ttraining's l2: 0.0859721\tvalid_1's l2: 11.7094\n",
      "[288]\ttraining's l2: 0.0853601\tvalid_1's l2: 11.6975\n",
      "[289]\ttraining's l2: 0.084709\tvalid_1's l2: 11.7015\n",
      "[290]\ttraining's l2: 0.084097\tvalid_1's l2: 11.6964\n",
      "[291]\ttraining's l2: 0.0834341\tvalid_1's l2: 11.7036\n",
      "[292]\ttraining's l2: 0.0828164\tvalid_1's l2: 11.7078\n",
      "[293]\ttraining's l2: 0.0821516\tvalid_1's l2: 11.7128\n",
      "[294]\ttraining's l2: 0.0815466\tvalid_1's l2: 11.7152\n",
      "[295]\ttraining's l2: 0.0809777\tvalid_1's l2: 11.7115\n",
      "[296]\ttraining's l2: 0.080386\tvalid_1's l2: 11.7\n",
      "[297]\ttraining's l2: 0.0797695\tvalid_1's l2: 11.7047\n",
      "[298]\ttraining's l2: 0.079169\tvalid_1's l2: 11.7114\n",
      "[299]\ttraining's l2: 0.0785768\tvalid_1's l2: 11.7176\n",
      "[300]\ttraining's l2: 0.0779927\tvalid_1's l2: 11.7086\n",
      "[1]\ttraining's l2: 69.612\tvalid_1's l2: 78.4826\n",
      "[2]\ttraining's l2: 57.5033\tvalid_1's l2: 65.9079\n",
      "[3]\ttraining's l2: 47.3389\tvalid_1's l2: 54.8992\n",
      "[4]\ttraining's l2: 39.2305\tvalid_1's l2: 46.9505\n",
      "[5]\ttraining's l2: 32.6163\tvalid_1's l2: 40.2629\n",
      "[6]\ttraining's l2: 27.0903\tvalid_1's l2: 34.5032\n",
      "[7]\ttraining's l2: 22.4801\tvalid_1's l2: 29.9499\n",
      "[8]\ttraining's l2: 18.7072\tvalid_1's l2: 26.2691\n",
      "[9]\ttraining's l2: 15.6084\tvalid_1's l2: 23.4843\n",
      "[10]\ttraining's l2: 13.0474\tvalid_1's l2: 21.0141\n",
      "[11]\ttraining's l2: 10.9437\tvalid_1's l2: 18.8579\n",
      "[12]\ttraining's l2: 9.18578\tvalid_1's l2: 17.2298\n",
      "[13]\ttraining's l2: 7.72996\tvalid_1's l2: 15.8449\n",
      "[14]\ttraining's l2: 6.59597\tvalid_1's l2: 14.7249\n",
      "[15]\ttraining's l2: 5.58697\tvalid_1's l2: 13.9607\n",
      "[16]\ttraining's l2: 4.78047\tvalid_1's l2: 13.35\n",
      "[17]\ttraining's l2: 4.04935\tvalid_1's l2: 12.7387\n",
      "[18]\ttraining's l2: 3.46108\tvalid_1's l2: 12.2557\n",
      "[19]\ttraining's l2: 2.97146\tvalid_1's l2: 11.9159\n",
      "[20]\ttraining's l2: 2.54681\tvalid_1's l2: 11.6203\n",
      "[21]\ttraining's l2: 2.21254\tvalid_1's l2: 11.4943\n",
      "[22]\ttraining's l2: 1.92118\tvalid_1's l2: 11.3316\n",
      "[23]\ttraining's l2: 1.67354\tvalid_1's l2: 11.1783\n",
      "[24]\ttraining's l2: 1.46626\tvalid_1's l2: 11.0766\n",
      "[25]\ttraining's l2: 1.29371\tvalid_1's l2: 11.0386\n",
      "[26]\ttraining's l2: 1.13928\tvalid_1's l2: 11.007\n",
      "[27]\ttraining's l2: 1.01304\tvalid_1's l2: 11.0077\n",
      "[28]\ttraining's l2: 0.901364\tvalid_1's l2: 10.9898\n",
      "[29]\ttraining's l2: 0.802129\tvalid_1's l2: 10.9402\n",
      "[30]\ttraining's l2: 0.720827\tvalid_1's l2: 10.9741\n",
      "[31]\ttraining's l2: 0.649163\tvalid_1's l2: 11.0293\n",
      "[32]\ttraining's l2: 0.587304\tvalid_1's l2: 11.0296\n",
      "[33]\ttraining's l2: 0.531014\tvalid_1's l2: 11.1005\n",
      "[34]\ttraining's l2: 0.484098\tvalid_1's l2: 11.1859\n",
      "[35]\ttraining's l2: 0.44153\tvalid_1's l2: 11.2183\n",
      "[36]\ttraining's l2: 0.405278\tvalid_1's l2: 11.2466\n",
      "[37]\ttraining's l2: 0.374794\tvalid_1's l2: 11.2841\n",
      "[38]\ttraining's l2: 0.345375\tvalid_1's l2: 11.301\n",
      "[39]\ttraining's l2: 0.316781\tvalid_1's l2: 11.332\n",
      "[40]\ttraining's l2: 0.294253\tvalid_1's l2: 11.3618\n",
      "[41]\ttraining's l2: 0.274942\tvalid_1's l2: 11.4125\n",
      "[42]\ttraining's l2: 0.255725\tvalid_1's l2: 11.4366\n",
      "[43]\ttraining's l2: 0.240275\tvalid_1's l2: 11.4719\n",
      "[44]\ttraining's l2: 0.225405\tvalid_1's l2: 11.4928\n",
      "[45]\ttraining's l2: 0.212814\tvalid_1's l2: 11.5027\n",
      "[46]\ttraining's l2: 0.201554\tvalid_1's l2: 11.5267\n",
      "[47]\ttraining's l2: 0.190377\tvalid_1's l2: 11.5374\n",
      "[48]\ttraining's l2: 0.18075\tvalid_1's l2: 11.553\n",
      "[49]\ttraining's l2: 0.171122\tvalid_1's l2: 11.5787\n",
      "[50]\ttraining's l2: 0.162107\tvalid_1's l2: 11.5947\n",
      "[51]\ttraining's l2: 0.153699\tvalid_1's l2: 11.625\n",
      "[52]\ttraining's l2: 0.14629\tvalid_1's l2: 11.6407\n",
      "[53]\ttraining's l2: 0.139168\tvalid_1's l2: 11.6467\n",
      "[54]\ttraining's l2: 0.133776\tvalid_1's l2: 11.6584\n",
      "[55]\ttraining's l2: 0.127817\tvalid_1's l2: 11.677\n",
      "[56]\ttraining's l2: 0.122551\tvalid_1's l2: 11.6938\n",
      "[57]\ttraining's l2: 0.117637\tvalid_1's l2: 11.6938\n",
      "[58]\ttraining's l2: 0.113729\tvalid_1's l2: 11.6913\n",
      "[59]\ttraining's l2: 0.109354\tvalid_1's l2: 11.7033\n",
      "[60]\ttraining's l2: 0.105864\tvalid_1's l2: 11.7161\n",
      "[61]\ttraining's l2: 0.102452\tvalid_1's l2: 11.7401\n",
      "[62]\ttraining's l2: 0.0992285\tvalid_1's l2: 11.7595\n",
      "[63]\ttraining's l2: 0.0954618\tvalid_1's l2: 11.7604\n",
      "[64]\ttraining's l2: 0.0907637\tvalid_1's l2: 11.7566\n",
      "[65]\ttraining's l2: 0.0879036\tvalid_1's l2: 11.7637\n",
      "[66]\ttraining's l2: 0.0854568\tvalid_1's l2: 11.7762\n",
      "[67]\ttraining's l2: 0.0834043\tvalid_1's l2: 11.7753\n",
      "[68]\ttraining's l2: 0.0806996\tvalid_1's l2: 11.7717\n",
      "[69]\ttraining's l2: 0.0784424\tvalid_1's l2: 11.7896\n",
      "[70]\ttraining's l2: 0.0746835\tvalid_1's l2: 11.8067\n",
      "[71]\ttraining's l2: 0.071376\tvalid_1's l2: 11.8145\n",
      "[72]\ttraining's l2: 0.0676226\tvalid_1's l2: 11.8443\n",
      "[73]\ttraining's l2: 0.065667\tvalid_1's l2: 11.8436\n",
      "[74]\ttraining's l2: 0.0633703\tvalid_1's l2: 11.8433\n",
      "[75]\ttraining's l2: 0.060721\tvalid_1's l2: 11.8562\n",
      "[76]\ttraining's l2: 0.058022\tvalid_1's l2: 11.864\n",
      "[77]\ttraining's l2: 0.0559881\tvalid_1's l2: 11.8708\n",
      "[78]\ttraining's l2: 0.0538839\tvalid_1's l2: 11.8689\n",
      "[79]\ttraining's l2: 0.0523831\tvalid_1's l2: 11.8704\n",
      "[80]\ttraining's l2: 0.0509669\tvalid_1's l2: 11.8655\n",
      "[81]\ttraining's l2: 0.0497504\tvalid_1's l2: 11.8648\n",
      "[82]\ttraining's l2: 0.0485027\tvalid_1's l2: 11.8668\n",
      "[83]\ttraining's l2: 0.0473608\tvalid_1's l2: 11.8647\n",
      "[84]\ttraining's l2: 0.04544\tvalid_1's l2: 11.8527\n",
      "[85]\ttraining's l2: 0.044428\tvalid_1's l2: 11.8548\n",
      "[86]\ttraining's l2: 0.0430167\tvalid_1's l2: 11.8645\n",
      "[87]\ttraining's l2: 0.0421374\tvalid_1's l2: 11.8596\n",
      "[88]\ttraining's l2: 0.0412541\tvalid_1's l2: 11.8638\n",
      "[89]\ttraining's l2: 0.0404418\tvalid_1's l2: 11.8747\n",
      "[90]\ttraining's l2: 0.039609\tvalid_1's l2: 11.8758\n",
      "[91]\ttraining's l2: 0.0383906\tvalid_1's l2: 11.8785\n",
      "[92]\ttraining's l2: 0.0375218\tvalid_1's l2: 11.8765\n",
      "[93]\ttraining's l2: 0.0364715\tvalid_1's l2: 11.8824\n",
      "[94]\ttraining's l2: 0.0354474\tvalid_1's l2: 11.8915\n",
      "[95]\ttraining's l2: 0.0347958\tvalid_1's l2: 11.8931\n",
      "[96]\ttraining's l2: 0.0341742\tvalid_1's l2: 11.8893\n",
      "[97]\ttraining's l2: 0.0335158\tvalid_1's l2: 11.8926\n",
      "[98]\ttraining's l2: 0.032854\tvalid_1's l2: 11.9019\n",
      "[99]\ttraining's l2: 0.0323031\tvalid_1's l2: 11.897\n",
      "[100]\ttraining's l2: 0.0314148\tvalid_1's l2: 11.9102\n",
      "[101]\ttraining's l2: 0.0308709\tvalid_1's l2: 11.8991\n",
      "[102]\ttraining's l2: 0.0302123\tvalid_1's l2: 11.8934\n",
      "[103]\ttraining's l2: 0.0296715\tvalid_1's l2: 11.8935\n",
      "[104]\ttraining's l2: 0.0291602\tvalid_1's l2: 11.8967\n",
      "[105]\ttraining's l2: 0.028598\tvalid_1's l2: 11.9\n",
      "[106]\ttraining's l2: 0.0280918\tvalid_1's l2: 11.8998\n",
      "[107]\ttraining's l2: 0.0276242\tvalid_1's l2: 11.8959\n",
      "[108]\ttraining's l2: 0.0271331\tvalid_1's l2: 11.8978\n",
      "[109]\ttraining's l2: 0.0267248\tvalid_1's l2: 11.9043\n",
      "[110]\ttraining's l2: 0.0260904\tvalid_1's l2: 11.9081\n",
      "[111]\ttraining's l2: 0.0256252\tvalid_1's l2: 11.9121\n",
      "[112]\ttraining's l2: 0.0252013\tvalid_1's l2: 11.9086\n",
      "[113]\ttraining's l2: 0.0245518\tvalid_1's l2: 11.8999\n",
      "[114]\ttraining's l2: 0.0241963\tvalid_1's l2: 11.8959\n",
      "[115]\ttraining's l2: 0.0238131\tvalid_1's l2: 11.8993\n",
      "[116]\ttraining's l2: 0.023257\tvalid_1's l2: 11.9\n",
      "[117]\ttraining's l2: 0.0228957\tvalid_1's l2: 11.9081\n",
      "[118]\ttraining's l2: 0.022532\tvalid_1's l2: 11.9025\n",
      "[119]\ttraining's l2: 0.0221644\tvalid_1's l2: 11.9055\n",
      "[120]\ttraining's l2: 0.0217472\tvalid_1's l2: 11.9045\n",
      "[121]\ttraining's l2: 0.0212087\tvalid_1's l2: 11.9084\n",
      "[122]\ttraining's l2: 0.0208732\tvalid_1's l2: 11.9058\n",
      "[123]\ttraining's l2: 0.0205463\tvalid_1's l2: 11.905\n",
      "[124]\ttraining's l2: 0.0199931\tvalid_1's l2: 11.9046\n",
      "[125]\ttraining's l2: 0.0196205\tvalid_1's l2: 11.9098\n",
      "[126]\ttraining's l2: 0.01927\tvalid_1's l2: 11.914\n",
      "[127]\ttraining's l2: 0.0189759\tvalid_1's l2: 11.9162\n",
      "[128]\ttraining's l2: 0.0187191\tvalid_1's l2: 11.9167\n",
      "[129]\ttraining's l2: 0.0184017\tvalid_1's l2: 11.9154\n",
      "[130]\ttraining's l2: 0.0181645\tvalid_1's l2: 11.9099\n",
      "[131]\ttraining's l2: 0.0178014\tvalid_1's l2: 11.9165\n",
      "[132]\ttraining's l2: 0.0175377\tvalid_1's l2: 11.9054\n",
      "[133]\ttraining's l2: 0.017302\tvalid_1's l2: 11.9068\n",
      "[134]\ttraining's l2: 0.0170158\tvalid_1's l2: 11.9094\n",
      "[135]\ttraining's l2: 0.0167384\tvalid_1's l2: 11.9125\n",
      "[136]\ttraining's l2: 0.0165292\tvalid_1's l2: 11.9181\n",
      "[137]\ttraining's l2: 0.0161555\tvalid_1's l2: 11.9198\n",
      "[138]\ttraining's l2: 0.0159091\tvalid_1's l2: 11.9141\n",
      "[139]\ttraining's l2: 0.0156049\tvalid_1's l2: 11.9158\n",
      "[140]\ttraining's l2: 0.0153676\tvalid_1's l2: 11.913\n",
      "[141]\ttraining's l2: 0.0151577\tvalid_1's l2: 11.9154\n",
      "[142]\ttraining's l2: 0.0149534\tvalid_1's l2: 11.9152\n",
      "[143]\ttraining's l2: 0.0146469\tvalid_1's l2: 11.9123\n",
      "[144]\ttraining's l2: 0.0143295\tvalid_1's l2: 11.9122\n",
      "[145]\ttraining's l2: 0.014122\tvalid_1's l2: 11.9093\n",
      "[146]\ttraining's l2: 0.0139422\tvalid_1's l2: 11.9023\n",
      "[147]\ttraining's l2: 0.0137512\tvalid_1's l2: 11.909\n",
      "[148]\ttraining's l2: 0.0135554\tvalid_1's l2: 11.9087\n",
      "[149]\ttraining's l2: 0.0133858\tvalid_1's l2: 11.9112\n",
      "[150]\ttraining's l2: 0.0132047\tvalid_1's l2: 11.9139\n",
      "[151]\ttraining's l2: 0.0130363\tvalid_1's l2: 11.917\n",
      "[152]\ttraining's l2: 0.0128085\tvalid_1's l2: 11.9178\n",
      "[153]\ttraining's l2: 0.0126518\tvalid_1's l2: 11.9232\n",
      "[154]\ttraining's l2: 0.012493\tvalid_1's l2: 11.9166\n",
      "[155]\ttraining's l2: 0.012326\tvalid_1's l2: 11.9149\n",
      "[156]\ttraining's l2: 0.0121017\tvalid_1's l2: 11.9145\n",
      "[157]\ttraining's l2: 0.0119384\tvalid_1's l2: 11.9162\n",
      "[158]\ttraining's l2: 0.0117924\tvalid_1's l2: 11.9151\n",
      "[159]\ttraining's l2: 0.0116465\tvalid_1's l2: 11.9128\n",
      "[160]\ttraining's l2: 0.011465\tvalid_1's l2: 11.9149\n",
      "[161]\ttraining's l2: 0.0113151\tvalid_1's l2: 11.9167\n",
      "[162]\ttraining's l2: 0.0111723\tvalid_1's l2: 11.913\n",
      "[163]\ttraining's l2: 0.0110478\tvalid_1's l2: 11.914\n",
      "[164]\ttraining's l2: 0.0109117\tvalid_1's l2: 11.9191\n",
      "[165]\ttraining's l2: 0.0107504\tvalid_1's l2: 11.9231\n",
      "[166]\ttraining's l2: 0.0105884\tvalid_1's l2: 11.9236\n",
      "[167]\ttraining's l2: 0.010467\tvalid_1's l2: 11.9252\n",
      "[168]\ttraining's l2: 0.0103246\tvalid_1's l2: 11.9277\n",
      "[169]\ttraining's l2: 0.0101844\tvalid_1's l2: 11.926\n",
      "[170]\ttraining's l2: 0.0100603\tvalid_1's l2: 11.9237\n",
      "[171]\ttraining's l2: 0.00989487\tvalid_1's l2: 11.9262\n",
      "[172]\ttraining's l2: 0.00976108\tvalid_1's l2: 11.9256\n",
      "[173]\ttraining's l2: 0.00962716\tvalid_1's l2: 11.9269\n",
      "[174]\ttraining's l2: 0.00950574\tvalid_1's l2: 11.9293\n",
      "[175]\ttraining's l2: 0.00935102\tvalid_1's l2: 11.9307\n",
      "[176]\ttraining's l2: 0.00923908\tvalid_1's l2: 11.9348\n",
      "[177]\ttraining's l2: 0.00907654\tvalid_1's l2: 11.9353\n",
      "[178]\ttraining's l2: 0.00897096\tvalid_1's l2: 11.9292\n",
      "[179]\ttraining's l2: 0.00886638\tvalid_1's l2: 11.9273\n",
      "[180]\ttraining's l2: 0.00877715\tvalid_1's l2: 11.9277\n",
      "[181]\ttraining's l2: 0.00867975\tvalid_1's l2: 11.9249\n",
      "[182]\ttraining's l2: 0.00857015\tvalid_1's l2: 11.9235\n",
      "[183]\ttraining's l2: 0.00846819\tvalid_1's l2: 11.9233\n",
      "[184]\ttraining's l2: 0.00837304\tvalid_1's l2: 11.9254\n",
      "[185]\ttraining's l2: 0.00825296\tvalid_1's l2: 11.9241\n",
      "[186]\ttraining's l2: 0.00816617\tvalid_1's l2: 11.9226\n",
      "[187]\ttraining's l2: 0.00806822\tvalid_1's l2: 11.9227\n",
      "[188]\ttraining's l2: 0.00794525\tvalid_1's l2: 11.9225\n",
      "[189]\ttraining's l2: 0.00786399\tvalid_1's l2: 11.9239\n",
      "[190]\ttraining's l2: 0.00776936\tvalid_1's l2: 11.924\n",
      "[191]\ttraining's l2: 0.00767855\tvalid_1's l2: 11.9252\n",
      "[192]\ttraining's l2: 0.00759441\tvalid_1's l2: 11.9258\n",
      "[193]\ttraining's l2: 0.00749609\tvalid_1's l2: 11.9264\n",
      "[194]\ttraining's l2: 0.00741237\tvalid_1's l2: 11.9235\n",
      "[195]\ttraining's l2: 0.00732884\tvalid_1's l2: 11.9209\n",
      "[196]\ttraining's l2: 0.00724809\tvalid_1's l2: 11.9233\n",
      "[197]\ttraining's l2: 0.00717062\tvalid_1's l2: 11.9216\n",
      "[198]\ttraining's l2: 0.00708567\tvalid_1's l2: 11.9262\n",
      "[199]\ttraining's l2: 0.00701226\tvalid_1's l2: 11.9268\n",
      "[200]\ttraining's l2: 0.00693676\tvalid_1's l2: 11.9289\n",
      "[201]\ttraining's l2: 0.00682701\tvalid_1's l2: 11.9287\n",
      "[202]\ttraining's l2: 0.006754\tvalid_1's l2: 11.927\n",
      "[203]\ttraining's l2: 0.00668419\tvalid_1's l2: 11.9254\n",
      "[204]\ttraining's l2: 0.00662163\tvalid_1's l2: 11.9216\n",
      "[205]\ttraining's l2: 0.006549\tvalid_1's l2: 11.9228\n",
      "[206]\ttraining's l2: 0.00647514\tvalid_1's l2: 11.9256\n",
      "[207]\ttraining's l2: 0.00641357\tvalid_1's l2: 11.9282\n",
      "[208]\ttraining's l2: 0.00634805\tvalid_1's l2: 11.9246\n",
      "[209]\ttraining's l2: 0.00627901\tvalid_1's l2: 11.9238\n",
      "[210]\ttraining's l2: 0.00621254\tvalid_1's l2: 11.9236\n",
      "[211]\ttraining's l2: 0.00614396\tvalid_1's l2: 11.9238\n",
      "[212]\ttraining's l2: 0.00607244\tvalid_1's l2: 11.9277\n",
      "[213]\ttraining's l2: 0.00600488\tvalid_1's l2: 11.929\n",
      "[214]\ttraining's l2: 0.00594045\tvalid_1's l2: 11.9292\n",
      "[215]\ttraining's l2: 0.00587935\tvalid_1's l2: 11.9262\n",
      "[216]\ttraining's l2: 0.00581786\tvalid_1's l2: 11.9253\n",
      "[217]\ttraining's l2: 0.00576259\tvalid_1's l2: 11.9263\n",
      "[218]\ttraining's l2: 0.00568761\tvalid_1's l2: 11.9272\n",
      "[219]\ttraining's l2: 0.00563324\tvalid_1's l2: 11.9259\n",
      "[220]\ttraining's l2: 0.00558063\tvalid_1's l2: 11.9238\n",
      "[221]\ttraining's l2: 0.00552045\tvalid_1's l2: 11.922\n",
      "[222]\ttraining's l2: 0.00546647\tvalid_1's l2: 11.9185\n",
      "[223]\ttraining's l2: 0.00541259\tvalid_1's l2: 11.9227\n",
      "[224]\ttraining's l2: 0.0053547\tvalid_1's l2: 11.924\n",
      "[225]\ttraining's l2: 0.00530308\tvalid_1's l2: 11.9255\n",
      "[226]\ttraining's l2: 0.00524225\tvalid_1's l2: 11.9247\n",
      "[227]\ttraining's l2: 0.00518707\tvalid_1's l2: 11.9248\n",
      "[228]\ttraining's l2: 0.0051334\tvalid_1's l2: 11.9221\n",
      "[229]\ttraining's l2: 0.00508198\tvalid_1's l2: 11.9229\n",
      "[230]\ttraining's l2: 0.00502947\tvalid_1's l2: 11.9223\n",
      "[231]\ttraining's l2: 0.00497773\tvalid_1's l2: 11.9205\n",
      "[232]\ttraining's l2: 0.00492795\tvalid_1's l2: 11.9214\n",
      "[233]\ttraining's l2: 0.00487863\tvalid_1's l2: 11.9224\n",
      "[234]\ttraining's l2: 0.00483191\tvalid_1's l2: 11.922\n",
      "[235]\ttraining's l2: 0.0047862\tvalid_1's l2: 11.9194\n",
      "[236]\ttraining's l2: 0.00473794\tvalid_1's l2: 11.9202\n",
      "[237]\ttraining's l2: 0.00469054\tvalid_1's l2: 11.924\n",
      "[238]\ttraining's l2: 0.00462828\tvalid_1's l2: 11.9217\n",
      "[239]\ttraining's l2: 0.00458748\tvalid_1's l2: 11.921\n",
      "[240]\ttraining's l2: 0.00453824\tvalid_1's l2: 11.9192\n",
      "[241]\ttraining's l2: 0.00449179\tvalid_1's l2: 11.9214\n",
      "[242]\ttraining's l2: 0.0044515\tvalid_1's l2: 11.9222\n",
      "[243]\ttraining's l2: 0.00440576\tvalid_1's l2: 11.9229\n",
      "[244]\ttraining's l2: 0.0043652\tvalid_1's l2: 11.9209\n",
      "[245]\ttraining's l2: 0.00432077\tvalid_1's l2: 11.9219\n",
      "[246]\ttraining's l2: 0.00427948\tvalid_1's l2: 11.92\n",
      "[247]\ttraining's l2: 0.00424098\tvalid_1's l2: 11.9175\n",
      "[248]\ttraining's l2: 0.00420116\tvalid_1's l2: 11.9169\n",
      "[249]\ttraining's l2: 0.00416302\tvalid_1's l2: 11.917\n",
      "[250]\ttraining's l2: 0.00412043\tvalid_1's l2: 11.9164\n",
      "[251]\ttraining's l2: 0.00407879\tvalid_1's l2: 11.9161\n",
      "[252]\ttraining's l2: 0.00403723\tvalid_1's l2: 11.9143\n",
      "[253]\ttraining's l2: 0.00400246\tvalid_1's l2: 11.9168\n",
      "[254]\ttraining's l2: 0.00396592\tvalid_1's l2: 11.9188\n",
      "[255]\ttraining's l2: 0.00391703\tvalid_1's l2: 11.9202\n",
      "[256]\ttraining's l2: 0.00387647\tvalid_1's l2: 11.9201\n",
      "[257]\ttraining's l2: 0.00383939\tvalid_1's l2: 11.9208\n",
      "[258]\ttraining's l2: 0.00379601\tvalid_1's l2: 11.9199\n",
      "[259]\ttraining's l2: 0.00375978\tvalid_1's l2: 11.9193\n",
      "[260]\ttraining's l2: 0.00372655\tvalid_1's l2: 11.92\n",
      "[261]\ttraining's l2: 0.00369137\tvalid_1's l2: 11.9191\n",
      "[262]\ttraining's l2: 0.00365416\tvalid_1's l2: 11.9193\n",
      "[263]\ttraining's l2: 0.00361996\tvalid_1's l2: 11.9185\n",
      "[264]\ttraining's l2: 0.00358481\tvalid_1's l2: 11.9176\n",
      "[265]\ttraining's l2: 0.0035531\tvalid_1's l2: 11.917\n",
      "[266]\ttraining's l2: 0.00351846\tvalid_1's l2: 11.9201\n",
      "[267]\ttraining's l2: 0.00348443\tvalid_1's l2: 11.9194\n",
      "[268]\ttraining's l2: 0.00345334\tvalid_1's l2: 11.9181\n",
      "[269]\ttraining's l2: 0.00342141\tvalid_1's l2: 11.9178\n",
      "[270]\ttraining's l2: 0.00338846\tvalid_1's l2: 11.9162\n",
      "[271]\ttraining's l2: 0.00334532\tvalid_1's l2: 11.9165\n",
      "[272]\ttraining's l2: 0.00331623\tvalid_1's l2: 11.9146\n",
      "[273]\ttraining's l2: 0.00328443\tvalid_1's l2: 11.9144\n",
      "[274]\ttraining's l2: 0.00324947\tvalid_1's l2: 11.9126\n",
      "[275]\ttraining's l2: 0.0032213\tvalid_1's l2: 11.9154\n",
      "[276]\ttraining's l2: 0.00319347\tvalid_1's l2: 11.9172\n",
      "[277]\ttraining's l2: 0.00316553\tvalid_1's l2: 11.9173\n",
      "[278]\ttraining's l2: 0.00313845\tvalid_1's l2: 11.9167\n",
      "[279]\ttraining's l2: 0.00310885\tvalid_1's l2: 11.9168\n",
      "[280]\ttraining's l2: 0.00308117\tvalid_1's l2: 11.9152\n",
      "[281]\ttraining's l2: 0.00305005\tvalid_1's l2: 11.9145\n",
      "[282]\ttraining's l2: 0.00301403\tvalid_1's l2: 11.9151\n",
      "[283]\ttraining's l2: 0.0029879\tvalid_1's l2: 11.9129\n",
      "[284]\ttraining's l2: 0.00295717\tvalid_1's l2: 11.9144\n",
      "[285]\ttraining's l2: 0.00293218\tvalid_1's l2: 11.9165\n",
      "[286]\ttraining's l2: 0.00290545\tvalid_1's l2: 11.9167\n",
      "[287]\ttraining's l2: 0.00287792\tvalid_1's l2: 11.9172\n",
      "[288]\ttraining's l2: 0.0028487\tvalid_1's l2: 11.9171\n",
      "[289]\ttraining's l2: 0.0028227\tvalid_1's l2: 11.9174\n",
      "[290]\ttraining's l2: 0.00279548\tvalid_1's l2: 11.9168\n",
      "[291]\ttraining's l2: 0.00276569\tvalid_1's l2: 11.9155\n",
      "[292]\ttraining's l2: 0.00274217\tvalid_1's l2: 11.917\n",
      "[293]\ttraining's l2: 0.00271939\tvalid_1's l2: 11.9164\n",
      "[294]\ttraining's l2: 0.00269245\tvalid_1's l2: 11.916\n",
      "[295]\ttraining's l2: 0.00266783\tvalid_1's l2: 11.9156\n",
      "[296]\ttraining's l2: 0.00263992\tvalid_1's l2: 11.9158\n",
      "[297]\ttraining's l2: 0.0026165\tvalid_1's l2: 11.9143\n",
      "[298]\ttraining's l2: 0.00259428\tvalid_1's l2: 11.9139\n",
      "[299]\ttraining's l2: 0.00257009\tvalid_1's l2: 11.9146\n",
      "[300]\ttraining's l2: 0.00254753\tvalid_1's l2: 11.9159\n",
      "[1]\ttraining's l2: 69.0379\tvalid_1's l2: 77.3922\n",
      "[2]\ttraining's l2: 56.4752\tvalid_1's l2: 64.4589\n",
      "[3]\ttraining's l2: 46.2686\tvalid_1's l2: 53.6465\n",
      "[4]\ttraining's l2: 37.9718\tvalid_1's l2: 45.2242\n",
      "[5]\ttraining's l2: 31.2224\tvalid_1's l2: 38.1816\n",
      "[6]\ttraining's l2: 25.7464\tvalid_1's l2: 32.9521\n",
      "[7]\ttraining's l2: 21.2387\tvalid_1's l2: 28.5075\n",
      "[8]\ttraining's l2: 17.5486\tvalid_1's l2: 24.7267\n",
      "[9]\ttraining's l2: 14.503\tvalid_1's l2: 21.9487\n",
      "[10]\ttraining's l2: 12.0289\tvalid_1's l2: 19.7372\n",
      "[11]\ttraining's l2: 9.98788\tvalid_1's l2: 17.7647\n",
      "[12]\ttraining's l2: 8.25569\tvalid_1's l2: 16.2255\n",
      "[13]\ttraining's l2: 6.85146\tvalid_1's l2: 14.883\n",
      "[14]\ttraining's l2: 5.72457\tvalid_1's l2: 13.9004\n",
      "[15]\ttraining's l2: 4.76982\tvalid_1's l2: 13.1431\n",
      "[16]\ttraining's l2: 4.00073\tvalid_1's l2: 12.503\n",
      "[17]\ttraining's l2: 3.35001\tvalid_1's l2: 11.9731\n",
      "[18]\ttraining's l2: 2.83647\tvalid_1's l2: 11.6006\n",
      "[19]\ttraining's l2: 2.40943\tvalid_1's l2: 11.3532\n",
      "[20]\ttraining's l2: 2.03509\tvalid_1's l2: 11.0567\n",
      "[21]\ttraining's l2: 1.74451\tvalid_1's l2: 10.9255\n",
      "[22]\ttraining's l2: 1.48759\tvalid_1's l2: 10.7454\n",
      "[23]\ttraining's l2: 1.28077\tvalid_1's l2: 10.5702\n",
      "[24]\ttraining's l2: 1.10437\tvalid_1's l2: 10.5083\n",
      "[25]\ttraining's l2: 0.956542\tvalid_1's l2: 10.5068\n",
      "[26]\ttraining's l2: 0.834275\tvalid_1's l2: 10.4853\n",
      "[27]\ttraining's l2: 0.730527\tvalid_1's l2: 10.4688\n",
      "[28]\ttraining's l2: 0.642675\tvalid_1's l2: 10.4563\n",
      "[29]\ttraining's l2: 0.568343\tvalid_1's l2: 10.5242\n",
      "[30]\ttraining's l2: 0.503418\tvalid_1's l2: 10.5143\n",
      "[31]\ttraining's l2: 0.44926\tvalid_1's l2: 10.545\n",
      "[32]\ttraining's l2: 0.404295\tvalid_1's l2: 10.5468\n",
      "[33]\ttraining's l2: 0.363676\tvalid_1's l2: 10.5697\n",
      "[34]\ttraining's l2: 0.329589\tvalid_1's l2: 10.6184\n",
      "[35]\ttraining's l2: 0.300409\tvalid_1's l2: 10.6409\n",
      "[36]\ttraining's l2: 0.273609\tvalid_1's l2: 10.6418\n",
      "[37]\ttraining's l2: 0.25099\tvalid_1's l2: 10.6833\n",
      "[38]\ttraining's l2: 0.231887\tvalid_1's l2: 10.7013\n",
      "[39]\ttraining's l2: 0.214935\tvalid_1's l2: 10.7269\n",
      "[40]\ttraining's l2: 0.19926\tvalid_1's l2: 10.7541\n",
      "[41]\ttraining's l2: 0.184707\tvalid_1's l2: 10.7693\n",
      "[42]\ttraining's l2: 0.17311\tvalid_1's l2: 10.7927\n",
      "[43]\ttraining's l2: 0.161842\tvalid_1's l2: 10.8109\n",
      "[44]\ttraining's l2: 0.15198\tvalid_1's l2: 10.8013\n",
      "[45]\ttraining's l2: 0.14279\tvalid_1's l2: 10.8168\n",
      "[46]\ttraining's l2: 0.134405\tvalid_1's l2: 10.8338\n",
      "[47]\ttraining's l2: 0.126617\tvalid_1's l2: 10.8565\n",
      "[48]\ttraining's l2: 0.119452\tvalid_1's l2: 10.8773\n",
      "[49]\ttraining's l2: 0.112981\tvalid_1's l2: 10.8731\n",
      "[50]\ttraining's l2: 0.107178\tvalid_1's l2: 10.8896\n",
      "[51]\ttraining's l2: 0.101263\tvalid_1's l2: 10.917\n",
      "[52]\ttraining's l2: 0.0965854\tvalid_1's l2: 10.9521\n",
      "[53]\ttraining's l2: 0.0914525\tvalid_1's l2: 10.9691\n",
      "[54]\ttraining's l2: 0.0875647\tvalid_1's l2: 10.9727\n",
      "[55]\ttraining's l2: 0.0834179\tvalid_1's l2: 10.9863\n",
      "[56]\ttraining's l2: 0.0795366\tvalid_1's l2: 10.9972\n",
      "[57]\ttraining's l2: 0.0765343\tvalid_1's l2: 10.9959\n",
      "[58]\ttraining's l2: 0.072844\tvalid_1's l2: 10.9953\n",
      "[59]\ttraining's l2: 0.0698458\tvalid_1's l2: 11.0205\n",
      "[60]\ttraining's l2: 0.067269\tvalid_1's l2: 11.0291\n",
      "[61]\ttraining's l2: 0.0642863\tvalid_1's l2: 11.042\n",
      "[62]\ttraining's l2: 0.0618681\tvalid_1's l2: 11.043\n",
      "[63]\ttraining's l2: 0.0595385\tvalid_1's l2: 11.0511\n",
      "[64]\ttraining's l2: 0.055963\tvalid_1's l2: 11.0605\n",
      "[65]\ttraining's l2: 0.0530173\tvalid_1's l2: 11.0621\n",
      "[66]\ttraining's l2: 0.0512576\tvalid_1's l2: 11.0624\n",
      "[67]\ttraining's l2: 0.04833\tvalid_1's l2: 11.0653\n",
      "[68]\ttraining's l2: 0.046725\tvalid_1's l2: 11.0838\n",
      "[69]\ttraining's l2: 0.0443723\tvalid_1's l2: 11.0915\n",
      "[70]\ttraining's l2: 0.042549\tvalid_1's l2: 11.1143\n",
      "[71]\ttraining's l2: 0.0412143\tvalid_1's l2: 11.1101\n",
      "[72]\ttraining's l2: 0.0399375\tvalid_1's l2: 11.1239\n",
      "[73]\ttraining's l2: 0.0378961\tvalid_1's l2: 11.1373\n",
      "[74]\ttraining's l2: 0.0365435\tvalid_1's l2: 11.1427\n",
      "[75]\ttraining's l2: 0.0355118\tvalid_1's l2: 11.1479\n",
      "[76]\ttraining's l2: 0.0343695\tvalid_1's l2: 11.1641\n",
      "[77]\ttraining's l2: 0.0327899\tvalid_1's l2: 11.1625\n",
      "[78]\ttraining's l2: 0.0314444\tvalid_1's l2: 11.1761\n",
      "[79]\ttraining's l2: 0.0306543\tvalid_1's l2: 11.1748\n",
      "[80]\ttraining's l2: 0.0299699\tvalid_1's l2: 11.1691\n",
      "[81]\ttraining's l2: 0.0292036\tvalid_1's l2: 11.1677\n",
      "[82]\ttraining's l2: 0.0285429\tvalid_1's l2: 11.1696\n",
      "[83]\ttraining's l2: 0.0275499\tvalid_1's l2: 11.1798\n",
      "[84]\ttraining's l2: 0.0268786\tvalid_1's l2: 11.181\n",
      "[85]\ttraining's l2: 0.0262233\tvalid_1's l2: 11.1902\n",
      "[86]\ttraining's l2: 0.0255812\tvalid_1's l2: 11.1913\n",
      "[87]\ttraining's l2: 0.0250399\tvalid_1's l2: 11.2019\n",
      "[88]\ttraining's l2: 0.0245248\tvalid_1's l2: 11.2\n",
      "[89]\ttraining's l2: 0.0240514\tvalid_1's l2: 11.2004\n",
      "[90]\ttraining's l2: 0.0235433\tvalid_1's l2: 11.2035\n",
      "[91]\ttraining's l2: 0.0227315\tvalid_1's l2: 11.2058\n",
      "[92]\ttraining's l2: 0.0222961\tvalid_1's l2: 11.2077\n",
      "[93]\ttraining's l2: 0.0219199\tvalid_1's l2: 11.2085\n",
      "[94]\ttraining's l2: 0.0214677\tvalid_1's l2: 11.2147\n",
      "[95]\ttraining's l2: 0.0210478\tvalid_1's l2: 11.2156\n",
      "[96]\ttraining's l2: 0.0206916\tvalid_1's l2: 11.2138\n",
      "[97]\ttraining's l2: 0.0201981\tvalid_1's l2: 11.2111\n",
      "[98]\ttraining's l2: 0.0198792\tvalid_1's l2: 11.211\n",
      "[99]\ttraining's l2: 0.0194468\tvalid_1's l2: 11.2167\n",
      "[100]\ttraining's l2: 0.0188503\tvalid_1's l2: 11.2194\n",
      "[101]\ttraining's l2: 0.0183946\tvalid_1's l2: 11.2252\n",
      "[102]\ttraining's l2: 0.0180258\tvalid_1's l2: 11.224\n",
      "[103]\ttraining's l2: 0.017651\tvalid_1's l2: 11.2251\n",
      "[104]\ttraining's l2: 0.017364\tvalid_1's l2: 11.2211\n",
      "[105]\ttraining's l2: 0.017041\tvalid_1's l2: 11.225\n",
      "[106]\ttraining's l2: 0.0167796\tvalid_1's l2: 11.227\n",
      "[107]\ttraining's l2: 0.0165335\tvalid_1's l2: 11.2267\n",
      "[108]\ttraining's l2: 0.0162827\tvalid_1's l2: 11.2316\n",
      "[109]\ttraining's l2: 0.0159527\tvalid_1's l2: 11.2272\n",
      "[110]\ttraining's l2: 0.0157502\tvalid_1's l2: 11.2269\n",
      "[111]\ttraining's l2: 0.0154551\tvalid_1's l2: 11.2261\n",
      "[112]\ttraining's l2: 0.0152404\tvalid_1's l2: 11.2281\n",
      "[113]\ttraining's l2: 0.0149768\tvalid_1's l2: 11.2237\n",
      "[114]\ttraining's l2: 0.014737\tvalid_1's l2: 11.2228\n",
      "[115]\ttraining's l2: 0.0145247\tvalid_1's l2: 11.2208\n",
      "[116]\ttraining's l2: 0.0142774\tvalid_1's l2: 11.2229\n",
      "[117]\ttraining's l2: 0.0140278\tvalid_1's l2: 11.2262\n",
      "[118]\ttraining's l2: 0.0138011\tvalid_1's l2: 11.2301\n",
      "[119]\ttraining's l2: 0.0136331\tvalid_1's l2: 11.2322\n",
      "[120]\ttraining's l2: 0.0134436\tvalid_1's l2: 11.2345\n",
      "[121]\ttraining's l2: 0.013255\tvalid_1's l2: 11.2335\n",
      "[122]\ttraining's l2: 0.0130544\tvalid_1's l2: 11.2344\n",
      "[123]\ttraining's l2: 0.012907\tvalid_1's l2: 11.2313\n",
      "[124]\ttraining's l2: 0.0126919\tvalid_1's l2: 11.2318\n",
      "[125]\ttraining's l2: 0.0125149\tvalid_1's l2: 11.2303\n",
      "[126]\ttraining's l2: 0.0123185\tvalid_1's l2: 11.2306\n",
      "[127]\ttraining's l2: 0.0121761\tvalid_1's l2: 11.2276\n",
      "[128]\ttraining's l2: 0.0119929\tvalid_1's l2: 11.226\n",
      "[129]\ttraining's l2: 0.0118419\tvalid_1's l2: 11.225\n",
      "[130]\ttraining's l2: 0.0116919\tvalid_1's l2: 11.2229\n",
      "[131]\ttraining's l2: 0.0115145\tvalid_1's l2: 11.219\n",
      "[132]\ttraining's l2: 0.0113816\tvalid_1's l2: 11.2221\n",
      "[133]\ttraining's l2: 0.0112559\tvalid_1's l2: 11.2236\n",
      "[134]\ttraining's l2: 0.0111176\tvalid_1's l2: 11.2239\n",
      "[135]\ttraining's l2: 0.0109762\tvalid_1's l2: 11.2249\n",
      "[136]\ttraining's l2: 0.0108652\tvalid_1's l2: 11.2239\n",
      "[137]\ttraining's l2: 0.0107276\tvalid_1's l2: 11.2231\n",
      "[138]\ttraining's l2: 0.0105998\tvalid_1's l2: 11.2232\n",
      "[139]\ttraining's l2: 0.0104927\tvalid_1's l2: 11.2226\n",
      "[140]\ttraining's l2: 0.0103683\tvalid_1's l2: 11.2217\n",
      "[141]\ttraining's l2: 0.0102541\tvalid_1's l2: 11.2211\n",
      "[142]\ttraining's l2: 0.0101342\tvalid_1's l2: 11.2188\n",
      "[143]\ttraining's l2: 0.0100177\tvalid_1's l2: 11.2194\n",
      "[144]\ttraining's l2: 0.00990131\tvalid_1's l2: 11.2197\n",
      "[145]\ttraining's l2: 0.00976972\tvalid_1's l2: 11.2227\n",
      "[146]\ttraining's l2: 0.00965119\tvalid_1's l2: 11.2219\n",
      "[147]\ttraining's l2: 0.00954562\tvalid_1's l2: 11.2241\n",
      "[148]\ttraining's l2: 0.00943564\tvalid_1's l2: 11.2241\n",
      "[149]\ttraining's l2: 0.00934192\tvalid_1's l2: 11.2243\n",
      "[150]\ttraining's l2: 0.00925292\tvalid_1's l2: 11.2223\n",
      "[151]\ttraining's l2: 0.00915966\tvalid_1's l2: 11.223\n",
      "[152]\ttraining's l2: 0.00907739\tvalid_1's l2: 11.2215\n",
      "[153]\ttraining's l2: 0.00898224\tvalid_1's l2: 11.2212\n",
      "[154]\ttraining's l2: 0.00888565\tvalid_1's l2: 11.2215\n",
      "[155]\ttraining's l2: 0.0087971\tvalid_1's l2: 11.2223\n",
      "[156]\ttraining's l2: 0.00869839\tvalid_1's l2: 11.2217\n",
      "[157]\ttraining's l2: 0.00861006\tvalid_1's l2: 11.2201\n",
      "[158]\ttraining's l2: 0.00851655\tvalid_1's l2: 11.2198\n",
      "[159]\ttraining's l2: 0.00843248\tvalid_1's l2: 11.2205\n",
      "[160]\ttraining's l2: 0.00834627\tvalid_1's l2: 11.2179\n",
      "[161]\ttraining's l2: 0.00826141\tvalid_1's l2: 11.2187\n",
      "[162]\ttraining's l2: 0.00818302\tvalid_1's l2: 11.2186\n",
      "[163]\ttraining's l2: 0.00809765\tvalid_1's l2: 11.2188\n",
      "[164]\ttraining's l2: 0.00801554\tvalid_1's l2: 11.2177\n",
      "[165]\ttraining's l2: 0.00793639\tvalid_1's l2: 11.2181\n",
      "[166]\ttraining's l2: 0.00786074\tvalid_1's l2: 11.2168\n",
      "[167]\ttraining's l2: 0.00779272\tvalid_1's l2: 11.2154\n",
      "[168]\ttraining's l2: 0.00771707\tvalid_1's l2: 11.216\n",
      "[169]\ttraining's l2: 0.00763566\tvalid_1's l2: 11.2181\n",
      "[170]\ttraining's l2: 0.00756216\tvalid_1's l2: 11.2166\n",
      "[171]\ttraining's l2: 0.00748726\tvalid_1's l2: 11.2196\n",
      "[172]\ttraining's l2: 0.00742098\tvalid_1's l2: 11.2192\n",
      "[173]\ttraining's l2: 0.00734974\tvalid_1's l2: 11.2214\n",
      "[174]\ttraining's l2: 0.00727995\tvalid_1's l2: 11.2215\n",
      "[175]\ttraining's l2: 0.00721171\tvalid_1's l2: 11.2198\n",
      "[176]\ttraining's l2: 0.00714741\tvalid_1's l2: 11.2184\n",
      "[177]\ttraining's l2: 0.00708353\tvalid_1's l2: 11.2175\n",
      "[178]\ttraining's l2: 0.00702019\tvalid_1's l2: 11.218\n",
      "[179]\ttraining's l2: 0.00696306\tvalid_1's l2: 11.2173\n",
      "[180]\ttraining's l2: 0.00690123\tvalid_1's l2: 11.2164\n",
      "[181]\ttraining's l2: 0.00684341\tvalid_1's l2: 11.2151\n",
      "[182]\ttraining's l2: 0.00678451\tvalid_1's l2: 11.2159\n",
      "[183]\ttraining's l2: 0.00672426\tvalid_1's l2: 11.2165\n",
      "[184]\ttraining's l2: 0.00666435\tvalid_1's l2: 11.2144\n",
      "[185]\ttraining's l2: 0.00660339\tvalid_1's l2: 11.2154\n",
      "[186]\ttraining's l2: 0.0065425\tvalid_1's l2: 11.2142\n",
      "[187]\ttraining's l2: 0.00648649\tvalid_1's l2: 11.2158\n",
      "[188]\ttraining's l2: 0.00642827\tvalid_1's l2: 11.2142\n",
      "[189]\ttraining's l2: 0.00637303\tvalid_1's l2: 11.2151\n",
      "[190]\ttraining's l2: 0.00631682\tvalid_1's l2: 11.2171\n",
      "[191]\ttraining's l2: 0.00626232\tvalid_1's l2: 11.216\n",
      "[192]\ttraining's l2: 0.00620976\tvalid_1's l2: 11.2172\n",
      "[193]\ttraining's l2: 0.00615954\tvalid_1's l2: 11.2179\n",
      "[194]\ttraining's l2: 0.00610725\tvalid_1's l2: 11.2175\n",
      "[195]\ttraining's l2: 0.00605833\tvalid_1's l2: 11.2161\n",
      "[196]\ttraining's l2: 0.00600825\tvalid_1's l2: 11.2165\n",
      "[197]\ttraining's l2: 0.00595781\tvalid_1's l2: 11.2168\n",
      "[198]\ttraining's l2: 0.00590864\tvalid_1's l2: 11.2166\n",
      "[199]\ttraining's l2: 0.00586113\tvalid_1's l2: 11.2166\n",
      "[200]\ttraining's l2: 0.00581328\tvalid_1's l2: 11.2151\n",
      "[201]\ttraining's l2: 0.00576267\tvalid_1's l2: 11.2137\n",
      "[202]\ttraining's l2: 0.00571672\tvalid_1's l2: 11.2144\n",
      "[203]\ttraining's l2: 0.00567049\tvalid_1's l2: 11.2154\n",
      "[204]\ttraining's l2: 0.00562202\tvalid_1's l2: 11.2148\n",
      "[205]\ttraining's l2: 0.00557428\tvalid_1's l2: 11.2138\n",
      "[206]\ttraining's l2: 0.00552561\tvalid_1's l2: 11.2127\n",
      "[207]\ttraining's l2: 0.00547922\tvalid_1's l2: 11.2145\n",
      "[208]\ttraining's l2: 0.00543516\tvalid_1's l2: 11.2142\n",
      "[209]\ttraining's l2: 0.00539352\tvalid_1's l2: 11.2162\n",
      "[210]\ttraining's l2: 0.00535255\tvalid_1's l2: 11.2154\n",
      "[211]\ttraining's l2: 0.00530906\tvalid_1's l2: 11.2153\n",
      "[212]\ttraining's l2: 0.00526706\tvalid_1's l2: 11.2135\n",
      "[213]\ttraining's l2: 0.00522541\tvalid_1's l2: 11.2125\n",
      "[214]\ttraining's l2: 0.00518442\tvalid_1's l2: 11.2133\n",
      "[215]\ttraining's l2: 0.00514416\tvalid_1's l2: 11.212\n",
      "[216]\ttraining's l2: 0.00510376\tvalid_1's l2: 11.2109\n",
      "[217]\ttraining's l2: 0.00506255\tvalid_1's l2: 11.2094\n",
      "[218]\ttraining's l2: 0.00502316\tvalid_1's l2: 11.2099\n",
      "[219]\ttraining's l2: 0.00498264\tvalid_1's l2: 11.2112\n",
      "[220]\ttraining's l2: 0.00494417\tvalid_1's l2: 11.211\n",
      "[221]\ttraining's l2: 0.0049058\tvalid_1's l2: 11.2126\n",
      "[222]\ttraining's l2: 0.00486748\tvalid_1's l2: 11.212\n",
      "[223]\ttraining's l2: 0.00482779\tvalid_1's l2: 11.2142\n",
      "[224]\ttraining's l2: 0.0047902\tvalid_1's l2: 11.2149\n",
      "[225]\ttraining's l2: 0.00475208\tvalid_1's l2: 11.2137\n",
      "[226]\ttraining's l2: 0.00471381\tvalid_1's l2: 11.2128\n",
      "[227]\ttraining's l2: 0.00467439\tvalid_1's l2: 11.2111\n",
      "[228]\ttraining's l2: 0.00463727\tvalid_1's l2: 11.21\n",
      "[229]\ttraining's l2: 0.0046\tvalid_1's l2: 11.2103\n",
      "[230]\ttraining's l2: 0.00456621\tvalid_1's l2: 11.2099\n",
      "[231]\ttraining's l2: 0.00453162\tvalid_1's l2: 11.2094\n",
      "[232]\ttraining's l2: 0.00449523\tvalid_1's l2: 11.2089\n",
      "[233]\ttraining's l2: 0.00445956\tvalid_1's l2: 11.2089\n",
      "[234]\ttraining's l2: 0.0044247\tvalid_1's l2: 11.2094\n",
      "[235]\ttraining's l2: 0.00439077\tvalid_1's l2: 11.2093\n",
      "[236]\ttraining's l2: 0.00435756\tvalid_1's l2: 11.2089\n",
      "[237]\ttraining's l2: 0.00432461\tvalid_1's l2: 11.2095\n",
      "[238]\ttraining's l2: 0.0042933\tvalid_1's l2: 11.2083\n",
      "[239]\ttraining's l2: 0.00426049\tvalid_1's l2: 11.2075\n",
      "[240]\ttraining's l2: 0.00422766\tvalid_1's l2: 11.2078\n",
      "[241]\ttraining's l2: 0.00419459\tvalid_1's l2: 11.2076\n",
      "[242]\ttraining's l2: 0.00416282\tvalid_1's l2: 11.2074\n",
      "[243]\ttraining's l2: 0.00413119\tvalid_1's l2: 11.2087\n",
      "[244]\ttraining's l2: 0.00409979\tvalid_1's l2: 11.2091\n",
      "[245]\ttraining's l2: 0.00406847\tvalid_1's l2: 11.2088\n",
      "[246]\ttraining's l2: 0.00403733\tvalid_1's l2: 11.2088\n",
      "[247]\ttraining's l2: 0.00400716\tvalid_1's l2: 11.2101\n",
      "[248]\ttraining's l2: 0.00397849\tvalid_1's l2: 11.2096\n",
      "[249]\ttraining's l2: 0.00394739\tvalid_1's l2: 11.2092\n",
      "[250]\ttraining's l2: 0.00391807\tvalid_1's l2: 11.2089\n",
      "[251]\ttraining's l2: 0.00388772\tvalid_1's l2: 11.2088\n",
      "[252]\ttraining's l2: 0.00385781\tvalid_1's l2: 11.2079\n",
      "[253]\ttraining's l2: 0.00382942\tvalid_1's l2: 11.2062\n",
      "[254]\ttraining's l2: 0.0038005\tvalid_1's l2: 11.2053\n",
      "[255]\ttraining's l2: 0.00377136\tvalid_1's l2: 11.2057\n",
      "[256]\ttraining's l2: 0.00374237\tvalid_1's l2: 11.2059\n",
      "[257]\ttraining's l2: 0.00371499\tvalid_1's l2: 11.2047\n",
      "[258]\ttraining's l2: 0.00368649\tvalid_1's l2: 11.2042\n",
      "[259]\ttraining's l2: 0.00365827\tvalid_1's l2: 11.2034\n",
      "[260]\ttraining's l2: 0.0036294\tvalid_1's l2: 11.202\n",
      "[261]\ttraining's l2: 0.00360282\tvalid_1's l2: 11.2038\n",
      "[262]\ttraining's l2: 0.00357668\tvalid_1's l2: 11.2045\n",
      "[263]\ttraining's l2: 0.0035491\tvalid_1's l2: 11.2035\n",
      "[264]\ttraining's l2: 0.00352212\tvalid_1's l2: 11.2027\n",
      "[265]\ttraining's l2: 0.00349483\tvalid_1's l2: 11.2016\n",
      "[266]\ttraining's l2: 0.00346826\tvalid_1's l2: 11.2028\n",
      "[267]\ttraining's l2: 0.00344419\tvalid_1's l2: 11.2023\n",
      "[268]\ttraining's l2: 0.00341838\tvalid_1's l2: 11.2026\n",
      "[269]\ttraining's l2: 0.00339285\tvalid_1's l2: 11.2018\n",
      "[270]\ttraining's l2: 0.00336863\tvalid_1's l2: 11.2019\n",
      "[271]\ttraining's l2: 0.00334382\tvalid_1's l2: 11.2029\n",
      "[272]\ttraining's l2: 0.00331968\tvalid_1's l2: 11.2023\n",
      "[273]\ttraining's l2: 0.00329615\tvalid_1's l2: 11.2018\n",
      "[274]\ttraining's l2: 0.00327246\tvalid_1's l2: 11.2002\n",
      "[275]\ttraining's l2: 0.00324922\tvalid_1's l2: 11.2012\n",
      "[276]\ttraining's l2: 0.00322531\tvalid_1's l2: 11.2013\n",
      "[277]\ttraining's l2: 0.0032029\tvalid_1's l2: 11.2008\n",
      "[278]\ttraining's l2: 0.00317943\tvalid_1's l2: 11.2005\n",
      "[279]\ttraining's l2: 0.00315485\tvalid_1's l2: 11.1995\n",
      "[280]\ttraining's l2: 0.00313056\tvalid_1's l2: 11.1993\n",
      "[281]\ttraining's l2: 0.00310605\tvalid_1's l2: 11.1982\n",
      "[282]\ttraining's l2: 0.00308237\tvalid_1's l2: 11.1978\n",
      "[283]\ttraining's l2: 0.00305973\tvalid_1's l2: 11.1971\n",
      "[284]\ttraining's l2: 0.00303809\tvalid_1's l2: 11.1988\n",
      "[285]\ttraining's l2: 0.00301463\tvalid_1's l2: 11.1978\n",
      "[286]\ttraining's l2: 0.00299254\tvalid_1's l2: 11.1998\n",
      "[287]\ttraining's l2: 0.00297051\tvalid_1's l2: 11.1994\n",
      "[288]\ttraining's l2: 0.00294867\tvalid_1's l2: 11.1989\n",
      "[289]\ttraining's l2: 0.00292756\tvalid_1's l2: 11.1979\n",
      "[290]\ttraining's l2: 0.00290715\tvalid_1's l2: 11.1983\n",
      "[291]\ttraining's l2: 0.00288699\tvalid_1's l2: 11.1974\n",
      "[292]\ttraining's l2: 0.00286509\tvalid_1's l2: 11.1969\n",
      "[293]\ttraining's l2: 0.00284259\tvalid_1's l2: 11.1961\n",
      "[294]\ttraining's l2: 0.00282185\tvalid_1's l2: 11.1949\n",
      "[295]\ttraining's l2: 0.00279914\tvalid_1's l2: 11.1947\n",
      "[296]\ttraining's l2: 0.00277849\tvalid_1's l2: 11.1941\n",
      "[297]\ttraining's l2: 0.00275856\tvalid_1's l2: 11.1951\n",
      "[298]\ttraining's l2: 0.00273797\tvalid_1's l2: 11.1945\n",
      "[299]\ttraining's l2: 0.00271879\tvalid_1's l2: 11.195\n",
      "[300]\ttraining's l2: 0.00269975\tvalid_1's l2: 11.1945\n",
      "[1]\ttraining's l2: 68.9392\tvalid_1's l2: 77.4197\n",
      "[2]\ttraining's l2: 56.2927\tvalid_1's l2: 63.9826\n",
      "[3]\ttraining's l2: 46.0056\tvalid_1's l2: 53.2358\n",
      "[4]\ttraining's l2: 37.6527\tvalid_1's l2: 44.8637\n",
      "[5]\ttraining's l2: 30.8371\tvalid_1's l2: 37.9874\n",
      "[6]\ttraining's l2: 25.2981\tvalid_1's l2: 32.524\n",
      "[7]\ttraining's l2: 20.798\tvalid_1's l2: 28.2484\n",
      "[8]\ttraining's l2: 17.1095\tvalid_1's l2: 24.8586\n",
      "[9]\ttraining's l2: 14.1128\tvalid_1's l2: 22.1217\n",
      "[10]\ttraining's l2: 11.6511\tvalid_1's l2: 19.8436\n",
      "[11]\ttraining's l2: 9.61941\tvalid_1's l2: 18.0587\n",
      "[12]\ttraining's l2: 7.94018\tvalid_1's l2: 16.8165\n",
      "[13]\ttraining's l2: 6.57882\tvalid_1's l2: 15.5677\n",
      "[14]\ttraining's l2: 5.45908\tvalid_1's l2: 14.7972\n",
      "[15]\ttraining's l2: 4.53975\tvalid_1's l2: 14.0306\n",
      "[16]\ttraining's l2: 3.78112\tvalid_1's l2: 13.406\n",
      "[17]\ttraining's l2: 3.1626\tvalid_1's l2: 12.918\n",
      "[18]\ttraining's l2: 2.65606\tvalid_1's l2: 12.4391\n",
      "[19]\ttraining's l2: 2.24625\tvalid_1's l2: 12.0924\n",
      "[20]\ttraining's l2: 1.89169\tvalid_1's l2: 11.822\n",
      "[21]\ttraining's l2: 1.60402\tvalid_1's l2: 11.6272\n",
      "[22]\ttraining's l2: 1.36392\tvalid_1's l2: 11.5048\n",
      "[23]\ttraining's l2: 1.16244\tvalid_1's l2: 11.3686\n",
      "[24]\ttraining's l2: 0.997917\tvalid_1's l2: 11.3336\n",
      "[25]\ttraining's l2: 0.861376\tvalid_1's l2: 11.2992\n",
      "[26]\ttraining's l2: 0.746199\tvalid_1's l2: 11.2573\n",
      "[27]\ttraining's l2: 0.650349\tvalid_1's l2: 11.2466\n",
      "[28]\ttraining's l2: 0.567724\tvalid_1's l2: 11.2688\n",
      "[29]\ttraining's l2: 0.498571\tvalid_1's l2: 11.2776\n",
      "[30]\ttraining's l2: 0.440491\tvalid_1's l2: 11.2629\n",
      "[31]\ttraining's l2: 0.391609\tvalid_1's l2: 11.2576\n",
      "[32]\ttraining's l2: 0.350339\tvalid_1's l2: 11.2732\n",
      "[33]\ttraining's l2: 0.315094\tvalid_1's l2: 11.2744\n",
      "[34]\ttraining's l2: 0.285526\tvalid_1's l2: 11.32\n",
      "[35]\ttraining's l2: 0.259777\tvalid_1's l2: 11.3486\n",
      "[36]\ttraining's l2: 0.236677\tvalid_1's l2: 11.3937\n",
      "[37]\ttraining's l2: 0.216573\tvalid_1's l2: 11.4334\n",
      "[38]\ttraining's l2: 0.199531\tvalid_1's l2: 11.4632\n",
      "[39]\ttraining's l2: 0.184492\tvalid_1's l2: 11.4766\n",
      "[40]\ttraining's l2: 0.171073\tvalid_1's l2: 11.5213\n",
      "[41]\ttraining's l2: 0.159091\tvalid_1's l2: 11.5319\n",
      "[42]\ttraining's l2: 0.148059\tvalid_1's l2: 11.5452\n",
      "[43]\ttraining's l2: 0.137744\tvalid_1's l2: 11.5714\n",
      "[44]\ttraining's l2: 0.128821\tvalid_1's l2: 11.5953\n",
      "[45]\ttraining's l2: 0.120088\tvalid_1's l2: 11.5973\n",
      "[46]\ttraining's l2: 0.11318\tvalid_1's l2: 11.5939\n",
      "[47]\ttraining's l2: 0.106703\tvalid_1's l2: 11.6135\n",
      "[48]\ttraining's l2: 0.100773\tvalid_1's l2: 11.6261\n",
      "[49]\ttraining's l2: 0.0952581\tvalid_1's l2: 11.644\n",
      "[50]\ttraining's l2: 0.0900011\tvalid_1's l2: 11.6625\n",
      "[51]\ttraining's l2: 0.0846516\tvalid_1's l2: 11.676\n",
      "[52]\ttraining's l2: 0.0807052\tvalid_1's l2: 11.6826\n",
      "[53]\ttraining's l2: 0.0767336\tvalid_1's l2: 11.7129\n",
      "[54]\ttraining's l2: 0.0732276\tvalid_1's l2: 11.7189\n",
      "[55]\ttraining's l2: 0.0698868\tvalid_1's l2: 11.7314\n",
      "[56]\ttraining's l2: 0.0666929\tvalid_1's l2: 11.7316\n",
      "[57]\ttraining's l2: 0.0637969\tvalid_1's l2: 11.741\n",
      "[58]\ttraining's l2: 0.0613852\tvalid_1's l2: 11.7512\n",
      "[59]\ttraining's l2: 0.0589375\tvalid_1's l2: 11.7699\n",
      "[60]\ttraining's l2: 0.0566572\tvalid_1's l2: 11.7844\n",
      "[61]\ttraining's l2: 0.0544277\tvalid_1's l2: 11.7827\n",
      "[62]\ttraining's l2: 0.0524007\tvalid_1's l2: 11.7912\n",
      "[63]\ttraining's l2: 0.0502982\tvalid_1's l2: 11.8014\n",
      "[64]\ttraining's l2: 0.0485848\tvalid_1's l2: 11.8165\n",
      "[65]\ttraining's l2: 0.0469094\tvalid_1's l2: 11.83\n",
      "[66]\ttraining's l2: 0.045401\tvalid_1's l2: 11.8318\n",
      "[67]\ttraining's l2: 0.0440311\tvalid_1's l2: 11.8442\n",
      "[68]\ttraining's l2: 0.0426427\tvalid_1's l2: 11.8457\n",
      "[69]\ttraining's l2: 0.041333\tvalid_1's l2: 11.8564\n",
      "[70]\ttraining's l2: 0.040224\tvalid_1's l2: 11.8601\n",
      "[71]\ttraining's l2: 0.0389461\tvalid_1's l2: 11.8616\n",
      "[72]\ttraining's l2: 0.0375939\tvalid_1's l2: 11.8713\n",
      "[73]\ttraining's l2: 0.036252\tvalid_1's l2: 11.8716\n",
      "[74]\ttraining's l2: 0.0351623\tvalid_1's l2: 11.879\n",
      "[75]\ttraining's l2: 0.0341301\tvalid_1's l2: 11.8824\n",
      "[76]\ttraining's l2: 0.033172\tvalid_1's l2: 11.8885\n",
      "[77]\ttraining's l2: 0.032116\tvalid_1's l2: 11.9009\n",
      "[78]\ttraining's l2: 0.0311917\tvalid_1's l2: 11.8987\n",
      "[79]\ttraining's l2: 0.0303953\tvalid_1's l2: 11.9057\n",
      "[80]\ttraining's l2: 0.0297316\tvalid_1's l2: 11.9142\n",
      "[81]\ttraining's l2: 0.0288051\tvalid_1's l2: 11.9155\n",
      "[82]\ttraining's l2: 0.0280359\tvalid_1's l2: 11.9128\n",
      "[83]\ttraining's l2: 0.0273752\tvalid_1's l2: 11.9134\n",
      "[84]\ttraining's l2: 0.0267963\tvalid_1's l2: 11.9159\n",
      "[85]\ttraining's l2: 0.0260558\tvalid_1's l2: 11.9156\n",
      "[86]\ttraining's l2: 0.025534\tvalid_1's l2: 11.9231\n",
      "[87]\ttraining's l2: 0.0249804\tvalid_1's l2: 11.9289\n",
      "[88]\ttraining's l2: 0.0244233\tvalid_1's l2: 11.9272\n",
      "[89]\ttraining's l2: 0.0238997\tvalid_1's l2: 11.9291\n",
      "[90]\ttraining's l2: 0.0234044\tvalid_1's l2: 11.936\n",
      "[91]\ttraining's l2: 0.0230253\tvalid_1's l2: 11.9432\n",
      "[92]\ttraining's l2: 0.022507\tvalid_1's l2: 11.9481\n",
      "[93]\ttraining's l2: 0.0219069\tvalid_1's l2: 11.951\n",
      "[94]\ttraining's l2: 0.0215202\tvalid_1's l2: 11.9496\n",
      "[95]\ttraining's l2: 0.0211027\tvalid_1's l2: 11.948\n",
      "[96]\ttraining's l2: 0.0206564\tvalid_1's l2: 11.9539\n",
      "[97]\ttraining's l2: 0.0203028\tvalid_1's l2: 11.9584\n",
      "[98]\ttraining's l2: 0.0198812\tvalid_1's l2: 11.965\n",
      "[99]\ttraining's l2: 0.0195707\tvalid_1's l2: 11.9735\n",
      "[100]\ttraining's l2: 0.0191776\tvalid_1's l2: 11.9739\n",
      "[101]\ttraining's l2: 0.0188875\tvalid_1's l2: 11.9717\n",
      "[102]\ttraining's l2: 0.0185562\tvalid_1's l2: 11.9703\n",
      "[103]\ttraining's l2: 0.0182767\tvalid_1's l2: 11.9711\n",
      "[104]\ttraining's l2: 0.0180276\tvalid_1's l2: 11.9785\n",
      "[105]\ttraining's l2: 0.0176749\tvalid_1's l2: 11.9779\n",
      "[106]\ttraining's l2: 0.0173276\tvalid_1's l2: 11.9773\n",
      "[107]\ttraining's l2: 0.0170859\tvalid_1's l2: 11.9758\n",
      "[108]\ttraining's l2: 0.0168164\tvalid_1's l2: 11.9725\n",
      "[109]\ttraining's l2: 0.0166147\tvalid_1's l2: 11.9795\n",
      "[110]\ttraining's l2: 0.0163906\tvalid_1's l2: 11.9784\n",
      "[111]\ttraining's l2: 0.0161449\tvalid_1's l2: 11.982\n",
      "[112]\ttraining's l2: 0.0159251\tvalid_1's l2: 11.9836\n",
      "[113]\ttraining's l2: 0.0157048\tvalid_1's l2: 11.9842\n",
      "[114]\ttraining's l2: 0.0155028\tvalid_1's l2: 11.9833\n",
      "[115]\ttraining's l2: 0.0152435\tvalid_1's l2: 11.9792\n",
      "[116]\ttraining's l2: 0.0150609\tvalid_1's l2: 11.9849\n",
      "[117]\ttraining's l2: 0.0148677\tvalid_1's l2: 11.9864\n",
      "[118]\ttraining's l2: 0.0146431\tvalid_1's l2: 11.9858\n",
      "[119]\ttraining's l2: 0.0144384\tvalid_1's l2: 11.9874\n",
      "[120]\ttraining's l2: 0.0142853\tvalid_1's l2: 11.9941\n",
      "[121]\ttraining's l2: 0.0140872\tvalid_1's l2: 11.9914\n",
      "[122]\ttraining's l2: 0.013868\tvalid_1's l2: 11.9857\n",
      "[123]\ttraining's l2: 0.0136949\tvalid_1's l2: 11.9911\n",
      "[124]\ttraining's l2: 0.0135068\tvalid_1's l2: 11.9901\n",
      "[125]\ttraining's l2: 0.0133236\tvalid_1's l2: 11.9927\n",
      "[126]\ttraining's l2: 0.0131905\tvalid_1's l2: 11.9933\n",
      "[127]\ttraining's l2: 0.0130025\tvalid_1's l2: 11.9913\n",
      "[128]\ttraining's l2: 0.0128649\tvalid_1's l2: 11.9962\n",
      "[129]\ttraining's l2: 0.0127104\tvalid_1's l2: 11.9934\n",
      "[130]\ttraining's l2: 0.0125498\tvalid_1's l2: 11.9919\n",
      "[131]\ttraining's l2: 0.0123955\tvalid_1's l2: 11.9945\n",
      "[132]\ttraining's l2: 0.0122864\tvalid_1's l2: 11.9946\n",
      "[133]\ttraining's l2: 0.0121465\tvalid_1's l2: 11.9931\n",
      "[134]\ttraining's l2: 0.0120271\tvalid_1's l2: 11.9987\n",
      "[135]\ttraining's l2: 0.0118801\tvalid_1's l2: 11.9996\n",
      "[136]\ttraining's l2: 0.0117511\tvalid_1's l2: 11.9993\n",
      "[137]\ttraining's l2: 0.0116429\tvalid_1's l2: 11.9993\n",
      "[138]\ttraining's l2: 0.0114852\tvalid_1's l2: 11.9976\n",
      "[139]\ttraining's l2: 0.0113466\tvalid_1's l2: 11.9941\n",
      "[140]\ttraining's l2: 0.0112393\tvalid_1's l2: 11.9976\n",
      "[141]\ttraining's l2: 0.0111082\tvalid_1's l2: 11.9966\n",
      "[142]\ttraining's l2: 0.0109841\tvalid_1's l2: 12.0019\n",
      "[143]\ttraining's l2: 0.0108687\tvalid_1's l2: 11.999\n",
      "[144]\ttraining's l2: 0.0107516\tvalid_1's l2: 12\n",
      "[145]\ttraining's l2: 0.0106126\tvalid_1's l2: 11.9972\n",
      "[146]\ttraining's l2: 0.0105152\tvalid_1's l2: 11.9968\n",
      "[147]\ttraining's l2: 0.010405\tvalid_1's l2: 11.9982\n",
      "[148]\ttraining's l2: 0.0103096\tvalid_1's l2: 11.999\n",
      "[149]\ttraining's l2: 0.0102063\tvalid_1's l2: 11.9975\n",
      "[150]\ttraining's l2: 0.0101026\tvalid_1's l2: 11.995\n",
      "[151]\ttraining's l2: 0.00998103\tvalid_1's l2: 11.9961\n",
      "[152]\ttraining's l2: 0.00986711\tvalid_1's l2: 11.9936\n",
      "[153]\ttraining's l2: 0.00977623\tvalid_1's l2: 11.998\n",
      "[154]\ttraining's l2: 0.0096796\tvalid_1's l2: 11.995\n",
      "[155]\ttraining's l2: 0.009577\tvalid_1's l2: 11.9956\n",
      "[156]\ttraining's l2: 0.00947203\tvalid_1's l2: 11.9921\n",
      "[157]\ttraining's l2: 0.00937871\tvalid_1's l2: 11.9961\n",
      "[158]\ttraining's l2: 0.00928459\tvalid_1's l2: 11.9974\n",
      "[159]\ttraining's l2: 0.00920441\tvalid_1's l2: 11.9973\n",
      "[160]\ttraining's l2: 0.00910618\tvalid_1's l2: 11.997\n",
      "[161]\ttraining's l2: 0.00901102\tvalid_1's l2: 11.9993\n",
      "[162]\ttraining's l2: 0.00892694\tvalid_1's l2: 12.0024\n",
      "[163]\ttraining's l2: 0.00884075\tvalid_1's l2: 12.0036\n",
      "[164]\ttraining's l2: 0.00874832\tvalid_1's l2: 12.0014\n",
      "[165]\ttraining's l2: 0.00867138\tvalid_1's l2: 12.0049\n",
      "[166]\ttraining's l2: 0.00858633\tvalid_1's l2: 12.0029\n",
      "[167]\ttraining's l2: 0.00851381\tvalid_1's l2: 12.0031\n",
      "[168]\ttraining's l2: 0.00843722\tvalid_1's l2: 12.0032\n",
      "[169]\ttraining's l2: 0.00835855\tvalid_1's l2: 12.0015\n",
      "[170]\ttraining's l2: 0.00828662\tvalid_1's l2: 12.0053\n",
      "[171]\ttraining's l2: 0.00820787\tvalid_1's l2: 12.0034\n",
      "[172]\ttraining's l2: 0.00812904\tvalid_1's l2: 12.0046\n",
      "[173]\ttraining's l2: 0.00804909\tvalid_1's l2: 12.0033\n",
      "[174]\ttraining's l2: 0.00797306\tvalid_1's l2: 12.0048\n",
      "[175]\ttraining's l2: 0.00789623\tvalid_1's l2: 12.0038\n",
      "[176]\ttraining's l2: 0.00782686\tvalid_1's l2: 12.0022\n",
      "[177]\ttraining's l2: 0.00775227\tvalid_1's l2: 12.0053\n",
      "[178]\ttraining's l2: 0.00768354\tvalid_1's l2: 12.0062\n",
      "[179]\ttraining's l2: 0.00762743\tvalid_1's l2: 12.0058\n",
      "[180]\ttraining's l2: 0.00755141\tvalid_1's l2: 12.0027\n",
      "[181]\ttraining's l2: 0.00748083\tvalid_1's l2: 12.0009\n",
      "[182]\ttraining's l2: 0.00741335\tvalid_1's l2: 12.0022\n",
      "[183]\ttraining's l2: 0.00734769\tvalid_1's l2: 12.0034\n",
      "[184]\ttraining's l2: 0.00727467\tvalid_1's l2: 12.0014\n",
      "[185]\ttraining's l2: 0.00721577\tvalid_1's l2: 12.0025\n",
      "[186]\ttraining's l2: 0.0071507\tvalid_1's l2: 12.0008\n",
      "[187]\ttraining's l2: 0.00709193\tvalid_1's l2: 12.0047\n",
      "[188]\ttraining's l2: 0.00702809\tvalid_1's l2: 12.0047\n",
      "[189]\ttraining's l2: 0.00696165\tvalid_1's l2: 12.005\n",
      "[190]\ttraining's l2: 0.00689726\tvalid_1's l2: 12.0086\n",
      "[191]\ttraining's l2: 0.00684324\tvalid_1's l2: 12.0078\n",
      "[192]\ttraining's l2: 0.00677976\tvalid_1's l2: 12.0074\n",
      "[193]\ttraining's l2: 0.00672465\tvalid_1's l2: 12.0103\n",
      "[194]\ttraining's l2: 0.0066597\tvalid_1's l2: 12.011\n",
      "[195]\ttraining's l2: 0.00659703\tvalid_1's l2: 12.0106\n",
      "[196]\ttraining's l2: 0.00653109\tvalid_1's l2: 12.0113\n",
      "[197]\ttraining's l2: 0.00647739\tvalid_1's l2: 12.01\n",
      "[198]\ttraining's l2: 0.00642236\tvalid_1's l2: 12.0098\n",
      "[199]\ttraining's l2: 0.00636321\tvalid_1's l2: 12.0114\n",
      "[200]\ttraining's l2: 0.00630585\tvalid_1's l2: 12.0115\n",
      "[201]\ttraining's l2: 0.00624901\tvalid_1's l2: 12.0099\n",
      "[202]\ttraining's l2: 0.00619931\tvalid_1's l2: 12.0102\n",
      "[203]\ttraining's l2: 0.00614558\tvalid_1's l2: 12.0091\n",
      "[204]\ttraining's l2: 0.00609939\tvalid_1's l2: 12.0076\n",
      "[205]\ttraining's l2: 0.00604722\tvalid_1's l2: 12.0071\n",
      "[206]\ttraining's l2: 0.00599331\tvalid_1's l2: 12.0049\n",
      "[207]\ttraining's l2: 0.00593893\tvalid_1's l2: 12.0063\n",
      "[208]\ttraining's l2: 0.00589095\tvalid_1's l2: 12.0095\n",
      "[209]\ttraining's l2: 0.00583993\tvalid_1's l2: 12.0088\n",
      "[210]\ttraining's l2: 0.00578885\tvalid_1's l2: 12.0101\n",
      "[211]\ttraining's l2: 0.00573875\tvalid_1's l2: 12.0085\n",
      "[212]\ttraining's l2: 0.00569035\tvalid_1's l2: 12.0092\n",
      "[213]\ttraining's l2: 0.00563929\tvalid_1's l2: 12.0066\n",
      "[214]\ttraining's l2: 0.00559129\tvalid_1's l2: 12.0058\n",
      "[215]\ttraining's l2: 0.00553867\tvalid_1's l2: 12.0083\n",
      "[216]\ttraining's l2: 0.00549517\tvalid_1's l2: 12.0071\n",
      "[217]\ttraining's l2: 0.00544955\tvalid_1's l2: 12.0075\n",
      "[218]\ttraining's l2: 0.00540439\tvalid_1's l2: 12.006\n",
      "[219]\ttraining's l2: 0.00535843\tvalid_1's l2: 12.0057\n",
      "[220]\ttraining's l2: 0.00531556\tvalid_1's l2: 12.0067\n",
      "[221]\ttraining's l2: 0.00526787\tvalid_1's l2: 12.0075\n",
      "[222]\ttraining's l2: 0.00521855\tvalid_1's l2: 12.0066\n",
      "[223]\ttraining's l2: 0.00517236\tvalid_1's l2: 12.0049\n",
      "[224]\ttraining's l2: 0.00512969\tvalid_1's l2: 12.0078\n",
      "[225]\ttraining's l2: 0.00507818\tvalid_1's l2: 12.0062\n",
      "[226]\ttraining's l2: 0.00503528\tvalid_1's l2: 12.0065\n",
      "[227]\ttraining's l2: 0.00499037\tvalid_1's l2: 12.0056\n",
      "[228]\ttraining's l2: 0.00495104\tvalid_1's l2: 12.0062\n",
      "[229]\ttraining's l2: 0.00490956\tvalid_1's l2: 12.0058\n",
      "[230]\ttraining's l2: 0.00486607\tvalid_1's l2: 12.0052\n",
      "[231]\ttraining's l2: 0.00482303\tvalid_1's l2: 12.0034\n",
      "[232]\ttraining's l2: 0.00478308\tvalid_1's l2: 12.0017\n",
      "[233]\ttraining's l2: 0.00474059\tvalid_1's l2: 12.0036\n",
      "[234]\ttraining's l2: 0.00469523\tvalid_1's l2: 12.0046\n",
      "[235]\ttraining's l2: 0.00465574\tvalid_1's l2: 12.0032\n",
      "[236]\ttraining's l2: 0.00462099\tvalid_1's l2: 12.0028\n",
      "[237]\ttraining's l2: 0.00458376\tvalid_1's l2: 12.0026\n",
      "[238]\ttraining's l2: 0.00455008\tvalid_1's l2: 12.0051\n",
      "[239]\ttraining's l2: 0.00451247\tvalid_1's l2: 12.0038\n",
      "[240]\ttraining's l2: 0.00447959\tvalid_1's l2: 12.0032\n",
      "[241]\ttraining's l2: 0.004439\tvalid_1's l2: 12.0057\n",
      "[242]\ttraining's l2: 0.00440463\tvalid_1's l2: 12.0048\n",
      "[243]\ttraining's l2: 0.00436595\tvalid_1's l2: 12.0049\n",
      "[244]\ttraining's l2: 0.00432437\tvalid_1's l2: 12.0049\n",
      "[245]\ttraining's l2: 0.00428797\tvalid_1's l2: 12.0039\n",
      "[246]\ttraining's l2: 0.00424982\tvalid_1's l2: 12.0045\n",
      "[247]\ttraining's l2: 0.00421219\tvalid_1's l2: 12.0033\n",
      "[248]\ttraining's l2: 0.00417847\tvalid_1's l2: 12.0023\n",
      "[249]\ttraining's l2: 0.00414427\tvalid_1's l2: 12.0023\n",
      "[250]\ttraining's l2: 0.0041082\tvalid_1's l2: 12.0042\n",
      "[251]\ttraining's l2: 0.00406836\tvalid_1's l2: 12.005\n",
      "[252]\ttraining's l2: 0.00403409\tvalid_1's l2: 12.0039\n",
      "[253]\ttraining's l2: 0.00400051\tvalid_1's l2: 12.0033\n",
      "[254]\ttraining's l2: 0.00396545\tvalid_1's l2: 12.0027\n",
      "[255]\ttraining's l2: 0.003935\tvalid_1's l2: 12.0049\n",
      "[256]\ttraining's l2: 0.00389621\tvalid_1's l2: 12.0024\n",
      "[257]\ttraining's l2: 0.00386135\tvalid_1's l2: 12.003\n",
      "[258]\ttraining's l2: 0.00382922\tvalid_1's l2: 12.0025\n",
      "[259]\ttraining's l2: 0.00380106\tvalid_1's l2: 12.0031\n",
      "[260]\ttraining's l2: 0.00376844\tvalid_1's l2: 12.0029\n",
      "[261]\ttraining's l2: 0.00373536\tvalid_1's l2: 12.0033\n",
      "[262]\ttraining's l2: 0.00370302\tvalid_1's l2: 12.0026\n",
      "[263]\ttraining's l2: 0.0036677\tvalid_1's l2: 12.0034\n",
      "[264]\ttraining's l2: 0.00364071\tvalid_1's l2: 12.0059\n",
      "[265]\ttraining's l2: 0.00361296\tvalid_1's l2: 12.0053\n",
      "[266]\ttraining's l2: 0.00357976\tvalid_1's l2: 12.0056\n",
      "[267]\ttraining's l2: 0.00355028\tvalid_1's l2: 12.0045\n",
      "[268]\ttraining's l2: 0.0035207\tvalid_1's l2: 12.0047\n",
      "[269]\ttraining's l2: 0.00348977\tvalid_1's l2: 12.0037\n",
      "[270]\ttraining's l2: 0.00345765\tvalid_1's l2: 12.0033\n",
      "[271]\ttraining's l2: 0.0034269\tvalid_1's l2: 12.0022\n",
      "[272]\ttraining's l2: 0.00340056\tvalid_1's l2: 12.0027\n",
      "[273]\ttraining's l2: 0.00337246\tvalid_1's l2: 12.0021\n",
      "[274]\ttraining's l2: 0.00334124\tvalid_1's l2: 12.001\n",
      "[275]\ttraining's l2: 0.00331329\tvalid_1's l2: 12.0024\n",
      "[276]\ttraining's l2: 0.00328987\tvalid_1's l2: 12.002\n",
      "[277]\ttraining's l2: 0.00326084\tvalid_1's l2: 12.0004\n",
      "[278]\ttraining's l2: 0.00323344\tvalid_1's l2: 11.999\n",
      "[279]\ttraining's l2: 0.00320722\tvalid_1's l2: 11.999\n",
      "[280]\ttraining's l2: 0.00317751\tvalid_1's l2: 11.9998\n",
      "[281]\ttraining's l2: 0.00315126\tvalid_1's l2: 12.0008\n",
      "[282]\ttraining's l2: 0.00312359\tvalid_1's l2: 11.9999\n",
      "[283]\ttraining's l2: 0.0030947\tvalid_1's l2: 11.9999\n",
      "[284]\ttraining's l2: 0.00307159\tvalid_1's l2: 12.0021\n",
      "[285]\ttraining's l2: 0.0030451\tvalid_1's l2: 12.0031\n",
      "[286]\ttraining's l2: 0.00302056\tvalid_1's l2: 12.0021\n",
      "[287]\ttraining's l2: 0.00299458\tvalid_1's l2: 12.0015\n",
      "[288]\ttraining's l2: 0.00296707\tvalid_1's l2: 11.9992\n",
      "[289]\ttraining's l2: 0.00294206\tvalid_1's l2: 11.9985\n",
      "[290]\ttraining's l2: 0.00291833\tvalid_1's l2: 11.9989\n",
      "[291]\ttraining's l2: 0.00289436\tvalid_1's l2: 11.9994\n",
      "[292]\ttraining's l2: 0.00287062\tvalid_1's l2: 11.999\n",
      "[293]\ttraining's l2: 0.00284372\tvalid_1's l2: 11.9995\n",
      "[294]\ttraining's l2: 0.00282083\tvalid_1's l2: 11.999\n",
      "[295]\ttraining's l2: 0.00279824\tvalid_1's l2: 11.9986\n",
      "[296]\ttraining's l2: 0.00277734\tvalid_1's l2: 11.9993\n",
      "[297]\ttraining's l2: 0.00275392\tvalid_1's l2: 11.9989\n",
      "[298]\ttraining's l2: 0.00273299\tvalid_1's l2: 11.9986\n",
      "[299]\ttraining's l2: 0.00271059\tvalid_1's l2: 11.9992\n",
      "[300]\ttraining's l2: 0.00268575\tvalid_1's l2: 11.9992\n",
      "10.918313812237708\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "stacking.train(X=train_X, y=train_y)\n",
    "print(np.mean(np.square(stacking.predict(test_X) - test_y)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}